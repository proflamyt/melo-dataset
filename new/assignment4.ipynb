{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlvp9kzp7PKD"
   },
   "source": [
    "#  **Deep Machine Learning Workshop 4**\n",
    "\n",
    "# Task 1 (Classification of MNIST Data using **Low** level API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mp1Wjc6r7flr"
   },
   "source": [
    "# Machine Learning Steps\n",
    "\n",
    "\n",
    "1.   Import and parse the dataset.\n",
    "2.   Define Model\n",
    "3.   Define loss function (Compile Model)\n",
    "4.   Train Model (Fit Model)\n",
    "5.   Evaulate Model (Optional Validation)   \n",
    "6.   Test Model (Prediction using Trained model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Tensorflow , numpy and metasploit libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4W_lEVMonguz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 18:13:16.454997: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-09 18:13:16.455020: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define learning rate (how quickly it approches the optimum ) *lr\n",
    "\n",
    "### Batch size number of training examples in one forward/backward propagation. The higher the batch size, the more memory space you'll need\n",
    "\n",
    "### Steps (Number of times it takes to train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "h0gCW8ANnmrA"
   },
   "outputs": [],
   "source": [
    "\n",
    "numClasses = 10\n",
    "numFeatures = 784\n",
    "\n",
    "lr = 0.15\n",
    "steps = 5000\n",
    "batchSize = 256\n",
    "iStep = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSzhtVZC_VS9"
   },
   "source": [
    "# Data\n",
    "\n",
    "## 1. Seprating the data into Training and Testing Data \n",
    "\n",
    "## 2. Reshape data to feature size\n",
    "\n",
    "## 3. Normalize the Data ( By Byte, Representing Each pixels with numbers between 1 and 0)\n",
    "    This is adviced for easier and lesser memory and time consuming computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdu1GgJCnpQz",
    "outputId": "b831765d-3d08-4efb-d50a-99a7eebaf21b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# MNIST data\n",
    "(xTrain, yTrain),(xTest, yTest) = mnist.load_data()\n",
    "xTrain, xTest = np.array(xTrain, np.float32), np.array(xTest, np.float32)\n",
    "xTrain, xTest = xTrain.reshape([-1,numFeatures]), xTest.reshape([-1,numFeatures])\n",
    "xTrain, xTest = xTrain/255., xTest/255.\n",
    "print(xTrain.shape, xTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Turn Train Data Into Slices and Shuffle \n",
    "### 2. initialize weights to 1 and bias to 0. weights will be updated during training\n",
    "        This is the starting point for the optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FUem2LZwnrd5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 18:13:22.316206: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-09 18:13:22.316270: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-09 18:13:22.316326: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (olamide): /proc/driver/nvidia/version does not exist\n",
      "2022-01-09 18:13:22.320973: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Shuffle and Batch\n",
    "trainData = tf.data.Dataset.from_tensor_slices((xTrain,yTrain))\n",
    "trainData = trainData.repeat().shuffle(5000).batch(batchSize).prefetch(1)\n",
    "\n",
    "# Weights\n",
    "W = tf.Variable(tf.ones([numFeatures, numClasses]), name = \"weights\")\n",
    "b = tf.Variable(tf.zeros([numClasses]), name = \"bias\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjuHTkL3_ZUt"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Activation Function (Softmax) :\n",
    "* This is used in multiclass classifications, Stays At the end of the blackbox to classify to diffrent classes based on their probability . picks the the class with the highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hdsDK2mrnur8"
   },
   "outputs": [],
   "source": [
    "def network(x):\n",
    "    return tf.nn.softmax(tf.matmul(x,W)+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qm4Gck_A_aVS"
   },
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tE84atF6-evZ"
   },
   "outputs": [],
   "source": [
    "def crossEntropy(y_pred, y_true):\n",
    "    y_true = tf.one_hot(y_true, depth=numClasses)\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-9,1.)\n",
    "    return tf.reduce_mean(tf.square(y_pred- y_true))\n",
    "    #return tf.reduce_mean(-tf.reduce_sum(y_true*tf.math.log(y_pred),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uphWEXsi_ce2"
   },
   "source": [
    "# Metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defines Metrics for Accuracy \n",
    "    * Compares the predicted values with the actual values and take its mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7OLs03v6-gPA"
   },
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    correctedPred = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correctedPred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYVvk0SP_m-1"
   },
   "source": [
    "# Training (Gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training The Data By Running Updating the weights and bias using stocastic gradient descent\n",
    "    * 1. Initializing a stochastic gradient descent optimizer with the learning rate declared earlier\n",
    "    * 2. Predict with Softmax \n",
    "    * 3. Check the loss with crossEntropy function\n",
    "    * 4. Generate gradient \n",
    "    * 5. update optimizer with the new gradient\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ClwRsUcI-iRH"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.SGD(lr)\n",
    "def runOptimization(x, y):\n",
    "    #print(x.shape, y.shape)\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = network(x)\n",
    "        loss = crossEntropy(pred, y)\n",
    "\n",
    "    gradients = g.gradient(loss, [W, b])\n",
    "    # print(gradients)\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "    return loss, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzUQvZif_uYq"
   },
   "source": [
    "# Training Loop using Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data\n",
    "    1. Updates weight step times , and check accuracy every 10 times , while storing the losses\n",
    "    \n",
    "####  Feedforward Propagation\n",
    "    The model optimize its weghts and bias by using this.first, the training data is run into the forward direction through the network. the next layer accepts the input data, processes through the softmax activation function and passes to the weight computed forward for optimization.\n",
    "    \n",
    "#### Backpropagation\n",
    "    This is optimizing the weights and bias by using the error computed in the previous iteration , it uses the crossentropy function as the cost funtion, the gradient descent tells which direction to optimize the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0tkScLw3nxDp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 10, loss: 0.089424, accuracy: 0.589844\n",
      "step: 20, loss: 0.088724, accuracy: 0.691406\n",
      "step: 30, loss: 0.087948, accuracy: 0.683594\n",
      "step: 40, loss: 0.087226, accuracy: 0.605469\n",
      "step: 50, loss: 0.086303, accuracy: 0.617188\n",
      "step: 60, loss: 0.085507, accuracy: 0.632812\n",
      "step: 70, loss: 0.084361, accuracy: 0.625000\n",
      "step: 80, loss: 0.083618, accuracy: 0.613281\n",
      "step: 90, loss: 0.083098, accuracy: 0.632812\n",
      "step: 100, loss: 0.081048, accuracy: 0.640625\n",
      "step: 110, loss: 0.081423, accuracy: 0.632812\n",
      "step: 120, loss: 0.079893, accuracy: 0.593750\n",
      "step: 130, loss: 0.078920, accuracy: 0.609375\n",
      "step: 140, loss: 0.076659, accuracy: 0.613281\n",
      "step: 150, loss: 0.076303, accuracy: 0.640625\n",
      "step: 160, loss: 0.075680, accuracy: 0.632812\n",
      "step: 170, loss: 0.074265, accuracy: 0.632812\n",
      "step: 180, loss: 0.071894, accuracy: 0.671875\n",
      "step: 190, loss: 0.070008, accuracy: 0.726562\n",
      "step: 200, loss: 0.071608, accuracy: 0.667969\n",
      "step: 210, loss: 0.069475, accuracy: 0.660156\n",
      "step: 220, loss: 0.068880, accuracy: 0.656250\n",
      "step: 230, loss: 0.067362, accuracy: 0.683594\n",
      "step: 240, loss: 0.064110, accuracy: 0.718750\n",
      "step: 250, loss: 0.065261, accuracy: 0.699219\n",
      "step: 260, loss: 0.064686, accuracy: 0.667969\n",
      "step: 270, loss: 0.062130, accuracy: 0.656250\n",
      "step: 280, loss: 0.064206, accuracy: 0.632812\n",
      "step: 290, loss: 0.057115, accuracy: 0.777344\n",
      "step: 300, loss: 0.062088, accuracy: 0.664062\n",
      "step: 310, loss: 0.056203, accuracy: 0.750000\n",
      "step: 320, loss: 0.060658, accuracy: 0.679688\n",
      "step: 330, loss: 0.054427, accuracy: 0.785156\n",
      "step: 340, loss: 0.054155, accuracy: 0.757812\n",
      "step: 350, loss: 0.058779, accuracy: 0.703125\n",
      "step: 360, loss: 0.057880, accuracy: 0.710938\n",
      "step: 370, loss: 0.053064, accuracy: 0.781250\n",
      "step: 380, loss: 0.054889, accuracy: 0.687500\n",
      "step: 390, loss: 0.054331, accuracy: 0.714844\n",
      "step: 400, loss: 0.053856, accuracy: 0.753906\n",
      "step: 410, loss: 0.051734, accuracy: 0.773438\n",
      "step: 420, loss: 0.052178, accuracy: 0.726562\n",
      "step: 430, loss: 0.051457, accuracy: 0.730469\n",
      "step: 440, loss: 0.048201, accuracy: 0.789062\n",
      "step: 450, loss: 0.047881, accuracy: 0.753906\n",
      "step: 460, loss: 0.048922, accuracy: 0.726562\n",
      "step: 470, loss: 0.049743, accuracy: 0.710938\n",
      "step: 480, loss: 0.046928, accuracy: 0.769531\n",
      "step: 490, loss: 0.044982, accuracy: 0.789062\n",
      "step: 500, loss: 0.045097, accuracy: 0.769531\n",
      "step: 510, loss: 0.045452, accuracy: 0.796875\n",
      "step: 520, loss: 0.045958, accuracy: 0.746094\n",
      "step: 530, loss: 0.044234, accuracy: 0.789062\n",
      "step: 540, loss: 0.045558, accuracy: 0.769531\n",
      "step: 550, loss: 0.044143, accuracy: 0.773438\n",
      "step: 560, loss: 0.044650, accuracy: 0.765625\n",
      "step: 570, loss: 0.042611, accuracy: 0.769531\n",
      "step: 580, loss: 0.043358, accuracy: 0.789062\n",
      "step: 590, loss: 0.043764, accuracy: 0.785156\n",
      "step: 600, loss: 0.043647, accuracy: 0.757812\n",
      "step: 610, loss: 0.039732, accuracy: 0.832031\n",
      "step: 620, loss: 0.043458, accuracy: 0.792969\n",
      "step: 630, loss: 0.042916, accuracy: 0.777344\n",
      "step: 640, loss: 0.039801, accuracy: 0.832031\n",
      "step: 650, loss: 0.041326, accuracy: 0.808594\n",
      "step: 660, loss: 0.039947, accuracy: 0.816406\n",
      "step: 670, loss: 0.039067, accuracy: 0.804688\n",
      "step: 680, loss: 0.040459, accuracy: 0.785156\n",
      "step: 690, loss: 0.039428, accuracy: 0.796875\n",
      "step: 700, loss: 0.036500, accuracy: 0.871094\n",
      "step: 710, loss: 0.036842, accuracy: 0.843750\n",
      "step: 720, loss: 0.039841, accuracy: 0.789062\n",
      "step: 730, loss: 0.037374, accuracy: 0.839844\n",
      "step: 740, loss: 0.035626, accuracy: 0.867188\n",
      "step: 750, loss: 0.039506, accuracy: 0.792969\n",
      "step: 760, loss: 0.040701, accuracy: 0.781250\n",
      "step: 770, loss: 0.037084, accuracy: 0.839844\n",
      "step: 780, loss: 0.034464, accuracy: 0.851562\n",
      "step: 790, loss: 0.040003, accuracy: 0.808594\n",
      "step: 800, loss: 0.037320, accuracy: 0.812500\n",
      "step: 810, loss: 0.039250, accuracy: 0.816406\n",
      "step: 820, loss: 0.036668, accuracy: 0.863281\n",
      "step: 830, loss: 0.037334, accuracy: 0.808594\n",
      "step: 840, loss: 0.035311, accuracy: 0.839844\n",
      "step: 850, loss: 0.033615, accuracy: 0.855469\n",
      "step: 860, loss: 0.036609, accuracy: 0.808594\n",
      "step: 870, loss: 0.035652, accuracy: 0.843750\n",
      "step: 880, loss: 0.032516, accuracy: 0.855469\n",
      "step: 890, loss: 0.030855, accuracy: 0.878906\n",
      "step: 900, loss: 0.035891, accuracy: 0.785156\n",
      "step: 910, loss: 0.032999, accuracy: 0.832031\n",
      "step: 920, loss: 0.028897, accuracy: 0.898438\n",
      "step: 930, loss: 0.035873, accuracy: 0.824219\n",
      "step: 940, loss: 0.030992, accuracy: 0.855469\n",
      "step: 950, loss: 0.029337, accuracy: 0.851562\n",
      "step: 960, loss: 0.032054, accuracy: 0.847656\n",
      "step: 970, loss: 0.032362, accuracy: 0.843750\n",
      "step: 980, loss: 0.034574, accuracy: 0.828125\n",
      "step: 990, loss: 0.033815, accuracy: 0.835938\n",
      "step: 1000, loss: 0.033451, accuracy: 0.820312\n",
      "step: 1010, loss: 0.028649, accuracy: 0.878906\n",
      "step: 1020, loss: 0.033684, accuracy: 0.816406\n",
      "step: 1030, loss: 0.035854, accuracy: 0.796875\n",
      "step: 1040, loss: 0.030533, accuracy: 0.859375\n",
      "step: 1050, loss: 0.031951, accuracy: 0.839844\n",
      "step: 1060, loss: 0.033434, accuracy: 0.839844\n",
      "step: 1070, loss: 0.028906, accuracy: 0.882812\n",
      "step: 1080, loss: 0.032501, accuracy: 0.859375\n",
      "step: 1090, loss: 0.031939, accuracy: 0.839844\n",
      "step: 1100, loss: 0.030041, accuracy: 0.828125\n",
      "step: 1110, loss: 0.026938, accuracy: 0.875000\n",
      "step: 1120, loss: 0.029568, accuracy: 0.835938\n",
      "step: 1130, loss: 0.028792, accuracy: 0.875000\n",
      "step: 1140, loss: 0.026224, accuracy: 0.882812\n",
      "step: 1150, loss: 0.030159, accuracy: 0.843750\n",
      "step: 1160, loss: 0.030303, accuracy: 0.839844\n",
      "step: 1170, loss: 0.030432, accuracy: 0.835938\n",
      "step: 1180, loss: 0.026232, accuracy: 0.871094\n",
      "step: 1190, loss: 0.030535, accuracy: 0.839844\n",
      "step: 1200, loss: 0.028209, accuracy: 0.867188\n",
      "step: 1210, loss: 0.025996, accuracy: 0.898438\n",
      "step: 1220, loss: 0.030274, accuracy: 0.859375\n",
      "step: 1230, loss: 0.029599, accuracy: 0.832031\n",
      "step: 1240, loss: 0.028525, accuracy: 0.847656\n",
      "step: 1250, loss: 0.028025, accuracy: 0.863281\n",
      "step: 1260, loss: 0.028520, accuracy: 0.855469\n",
      "step: 1270, loss: 0.030733, accuracy: 0.839844\n",
      "step: 1280, loss: 0.032895, accuracy: 0.824219\n",
      "step: 1290, loss: 0.033770, accuracy: 0.816406\n",
      "step: 1300, loss: 0.032486, accuracy: 0.824219\n",
      "step: 1310, loss: 0.030831, accuracy: 0.828125\n",
      "step: 1320, loss: 0.028032, accuracy: 0.859375\n",
      "step: 1330, loss: 0.030350, accuracy: 0.816406\n",
      "step: 1340, loss: 0.030495, accuracy: 0.882812\n",
      "step: 1350, loss: 0.029445, accuracy: 0.839844\n",
      "step: 1360, loss: 0.032290, accuracy: 0.800781\n",
      "step: 1370, loss: 0.027848, accuracy: 0.847656\n",
      "step: 1380, loss: 0.025508, accuracy: 0.871094\n",
      "step: 1390, loss: 0.026310, accuracy: 0.847656\n",
      "step: 1400, loss: 0.024618, accuracy: 0.878906\n",
      "step: 1410, loss: 0.028519, accuracy: 0.843750\n",
      "step: 1420, loss: 0.023917, accuracy: 0.882812\n",
      "step: 1430, loss: 0.026391, accuracy: 0.878906\n",
      "step: 1440, loss: 0.026500, accuracy: 0.859375\n",
      "step: 1450, loss: 0.025074, accuracy: 0.875000\n",
      "step: 1460, loss: 0.026733, accuracy: 0.859375\n",
      "step: 1470, loss: 0.028381, accuracy: 0.851562\n",
      "step: 1480, loss: 0.028942, accuracy: 0.851562\n",
      "step: 1490, loss: 0.026503, accuracy: 0.835938\n",
      "step: 1500, loss: 0.025802, accuracy: 0.878906\n",
      "step: 1510, loss: 0.029576, accuracy: 0.820312\n",
      "step: 1520, loss: 0.029386, accuracy: 0.820312\n",
      "step: 1530, loss: 0.025474, accuracy: 0.902344\n",
      "step: 1540, loss: 0.027066, accuracy: 0.855469\n",
      "step: 1550, loss: 0.027963, accuracy: 0.855469\n",
      "step: 1560, loss: 0.027094, accuracy: 0.863281\n",
      "step: 1570, loss: 0.027744, accuracy: 0.847656\n",
      "step: 1580, loss: 0.026795, accuracy: 0.886719\n",
      "step: 1590, loss: 0.027475, accuracy: 0.863281\n",
      "step: 1600, loss: 0.027671, accuracy: 0.843750\n",
      "step: 1610, loss: 0.024744, accuracy: 0.843750\n",
      "step: 1620, loss: 0.022579, accuracy: 0.894531\n",
      "step: 1630, loss: 0.025507, accuracy: 0.867188\n",
      "step: 1640, loss: 0.025469, accuracy: 0.863281\n",
      "step: 1650, loss: 0.025949, accuracy: 0.867188\n",
      "step: 1660, loss: 0.028247, accuracy: 0.835938\n",
      "step: 1670, loss: 0.024013, accuracy: 0.875000\n",
      "step: 1680, loss: 0.028430, accuracy: 0.824219\n",
      "step: 1690, loss: 0.024737, accuracy: 0.871094\n",
      "step: 1700, loss: 0.028059, accuracy: 0.828125\n",
      "step: 1710, loss: 0.027658, accuracy: 0.851562\n",
      "step: 1720, loss: 0.025166, accuracy: 0.875000\n",
      "step: 1730, loss: 0.025617, accuracy: 0.859375\n",
      "step: 1740, loss: 0.024166, accuracy: 0.867188\n",
      "step: 1750, loss: 0.024532, accuracy: 0.894531\n",
      "step: 1760, loss: 0.023938, accuracy: 0.875000\n",
      "step: 1770, loss: 0.025661, accuracy: 0.859375\n",
      "step: 1780, loss: 0.024805, accuracy: 0.882812\n",
      "step: 1790, loss: 0.025892, accuracy: 0.867188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1800, loss: 0.023088, accuracy: 0.871094\n",
      "step: 1810, loss: 0.028145, accuracy: 0.835938\n",
      "step: 1820, loss: 0.026951, accuracy: 0.859375\n",
      "step: 1830, loss: 0.026187, accuracy: 0.855469\n",
      "step: 1840, loss: 0.022815, accuracy: 0.898438\n",
      "step: 1850, loss: 0.024673, accuracy: 0.855469\n",
      "step: 1860, loss: 0.021150, accuracy: 0.886719\n",
      "step: 1870, loss: 0.022389, accuracy: 0.890625\n",
      "step: 1880, loss: 0.019860, accuracy: 0.902344\n",
      "step: 1890, loss: 0.022310, accuracy: 0.894531\n",
      "step: 1900, loss: 0.021284, accuracy: 0.902344\n",
      "step: 1910, loss: 0.024146, accuracy: 0.847656\n",
      "step: 1920, loss: 0.024154, accuracy: 0.871094\n",
      "step: 1930, loss: 0.023442, accuracy: 0.878906\n",
      "step: 1940, loss: 0.021578, accuracy: 0.894531\n",
      "step: 1950, loss: 0.024121, accuracy: 0.878906\n",
      "step: 1960, loss: 0.024536, accuracy: 0.882812\n",
      "step: 1970, loss: 0.023149, accuracy: 0.867188\n",
      "step: 1980, loss: 0.024430, accuracy: 0.855469\n",
      "step: 1990, loss: 0.027363, accuracy: 0.839844\n",
      "step: 2000, loss: 0.024874, accuracy: 0.867188\n",
      "step: 2010, loss: 0.021840, accuracy: 0.890625\n",
      "step: 2020, loss: 0.028339, accuracy: 0.835938\n",
      "step: 2030, loss: 0.026545, accuracy: 0.820312\n",
      "step: 2040, loss: 0.023628, accuracy: 0.886719\n",
      "step: 2050, loss: 0.026949, accuracy: 0.835938\n",
      "step: 2060, loss: 0.025225, accuracy: 0.855469\n",
      "step: 2070, loss: 0.020978, accuracy: 0.886719\n",
      "step: 2080, loss: 0.021155, accuracy: 0.898438\n",
      "step: 2090, loss: 0.022210, accuracy: 0.890625\n",
      "step: 2100, loss: 0.023469, accuracy: 0.863281\n",
      "step: 2110, loss: 0.021559, accuracy: 0.894531\n",
      "step: 2120, loss: 0.025306, accuracy: 0.855469\n",
      "step: 2130, loss: 0.023916, accuracy: 0.871094\n",
      "step: 2140, loss: 0.024914, accuracy: 0.843750\n",
      "step: 2150, loss: 0.021956, accuracy: 0.875000\n",
      "step: 2160, loss: 0.025085, accuracy: 0.863281\n",
      "step: 2170, loss: 0.022734, accuracy: 0.871094\n",
      "step: 2180, loss: 0.024725, accuracy: 0.871094\n",
      "step: 2190, loss: 0.023085, accuracy: 0.894531\n",
      "step: 2200, loss: 0.023152, accuracy: 0.886719\n",
      "step: 2210, loss: 0.025278, accuracy: 0.851562\n",
      "step: 2220, loss: 0.019217, accuracy: 0.914062\n",
      "step: 2230, loss: 0.026648, accuracy: 0.863281\n",
      "step: 2240, loss: 0.023244, accuracy: 0.871094\n",
      "step: 2250, loss: 0.021798, accuracy: 0.890625\n",
      "step: 2260, loss: 0.024182, accuracy: 0.851562\n",
      "step: 2270, loss: 0.025801, accuracy: 0.843750\n",
      "step: 2280, loss: 0.024904, accuracy: 0.859375\n",
      "step: 2290, loss: 0.026304, accuracy: 0.832031\n",
      "step: 2300, loss: 0.022552, accuracy: 0.902344\n",
      "step: 2310, loss: 0.023619, accuracy: 0.871094\n",
      "step: 2320, loss: 0.019631, accuracy: 0.917969\n",
      "step: 2330, loss: 0.021045, accuracy: 0.886719\n",
      "step: 2340, loss: 0.022072, accuracy: 0.867188\n",
      "step: 2350, loss: 0.022793, accuracy: 0.878906\n",
      "step: 2360, loss: 0.017933, accuracy: 0.910156\n",
      "step: 2370, loss: 0.020689, accuracy: 0.906250\n",
      "step: 2380, loss: 0.024195, accuracy: 0.851562\n",
      "step: 2390, loss: 0.024895, accuracy: 0.855469\n",
      "step: 2400, loss: 0.020862, accuracy: 0.890625\n",
      "step: 2410, loss: 0.022569, accuracy: 0.875000\n",
      "step: 2420, loss: 0.022643, accuracy: 0.878906\n",
      "step: 2430, loss: 0.024474, accuracy: 0.839844\n",
      "step: 2440, loss: 0.025364, accuracy: 0.855469\n",
      "step: 2450, loss: 0.024105, accuracy: 0.875000\n",
      "step: 2460, loss: 0.020438, accuracy: 0.894531\n",
      "step: 2470, loss: 0.022545, accuracy: 0.882812\n",
      "step: 2480, loss: 0.020086, accuracy: 0.910156\n",
      "step: 2490, loss: 0.020429, accuracy: 0.910156\n",
      "step: 2500, loss: 0.022402, accuracy: 0.882812\n",
      "step: 2510, loss: 0.022845, accuracy: 0.886719\n",
      "step: 2520, loss: 0.021553, accuracy: 0.902344\n",
      "step: 2530, loss: 0.024163, accuracy: 0.847656\n",
      "step: 2540, loss: 0.021064, accuracy: 0.878906\n",
      "step: 2550, loss: 0.018345, accuracy: 0.914062\n",
      "step: 2560, loss: 0.022395, accuracy: 0.875000\n",
      "step: 2570, loss: 0.021135, accuracy: 0.902344\n",
      "step: 2580, loss: 0.019813, accuracy: 0.902344\n",
      "step: 2590, loss: 0.019321, accuracy: 0.898438\n",
      "step: 2600, loss: 0.020139, accuracy: 0.894531\n",
      "step: 2610, loss: 0.020784, accuracy: 0.878906\n",
      "step: 2620, loss: 0.023523, accuracy: 0.867188\n",
      "step: 2630, loss: 0.023538, accuracy: 0.871094\n",
      "step: 2640, loss: 0.023428, accuracy: 0.867188\n",
      "step: 2650, loss: 0.021376, accuracy: 0.882812\n",
      "step: 2660, loss: 0.021025, accuracy: 0.890625\n",
      "step: 2670, loss: 0.022934, accuracy: 0.871094\n",
      "step: 2680, loss: 0.023490, accuracy: 0.867188\n",
      "step: 2690, loss: 0.019848, accuracy: 0.890625\n",
      "step: 2700, loss: 0.021444, accuracy: 0.871094\n",
      "step: 2710, loss: 0.024981, accuracy: 0.847656\n",
      "step: 2720, loss: 0.023841, accuracy: 0.859375\n",
      "step: 2730, loss: 0.022286, accuracy: 0.871094\n",
      "step: 2740, loss: 0.022891, accuracy: 0.875000\n",
      "step: 2750, loss: 0.019207, accuracy: 0.882812\n",
      "step: 2760, loss: 0.020447, accuracy: 0.875000\n",
      "step: 2770, loss: 0.022982, accuracy: 0.894531\n",
      "step: 2780, loss: 0.020294, accuracy: 0.882812\n",
      "step: 2790, loss: 0.015295, accuracy: 0.925781\n",
      "step: 2800, loss: 0.022087, accuracy: 0.875000\n",
      "step: 2810, loss: 0.021250, accuracy: 0.875000\n",
      "step: 2820, loss: 0.016563, accuracy: 0.914062\n",
      "step: 2830, loss: 0.020759, accuracy: 0.878906\n",
      "step: 2840, loss: 0.024726, accuracy: 0.859375\n",
      "step: 2850, loss: 0.025898, accuracy: 0.832031\n",
      "step: 2860, loss: 0.020119, accuracy: 0.894531\n",
      "step: 2870, loss: 0.023752, accuracy: 0.859375\n",
      "step: 2880, loss: 0.022014, accuracy: 0.859375\n",
      "step: 2890, loss: 0.019554, accuracy: 0.878906\n",
      "step: 2900, loss: 0.018115, accuracy: 0.894531\n",
      "step: 2910, loss: 0.019203, accuracy: 0.898438\n",
      "step: 2920, loss: 0.020679, accuracy: 0.882812\n",
      "step: 2930, loss: 0.022422, accuracy: 0.859375\n",
      "step: 2940, loss: 0.027406, accuracy: 0.835938\n",
      "step: 2950, loss: 0.022169, accuracy: 0.878906\n",
      "step: 2960, loss: 0.022896, accuracy: 0.863281\n",
      "step: 2970, loss: 0.021973, accuracy: 0.875000\n",
      "step: 2980, loss: 0.020655, accuracy: 0.890625\n",
      "step: 2990, loss: 0.023617, accuracy: 0.839844\n",
      "step: 3000, loss: 0.026157, accuracy: 0.843750\n",
      "step: 3010, loss: 0.020266, accuracy: 0.882812\n",
      "step: 3020, loss: 0.021852, accuracy: 0.871094\n",
      "step: 3030, loss: 0.021135, accuracy: 0.867188\n",
      "step: 3040, loss: 0.017424, accuracy: 0.921875\n",
      "step: 3050, loss: 0.016900, accuracy: 0.921875\n",
      "step: 3060, loss: 0.018188, accuracy: 0.914062\n",
      "step: 3070, loss: 0.018713, accuracy: 0.894531\n",
      "step: 3080, loss: 0.022013, accuracy: 0.871094\n",
      "step: 3090, loss: 0.021313, accuracy: 0.886719\n",
      "step: 3100, loss: 0.018038, accuracy: 0.898438\n",
      "step: 3110, loss: 0.017026, accuracy: 0.929688\n",
      "step: 3120, loss: 0.019832, accuracy: 0.882812\n",
      "step: 3130, loss: 0.021106, accuracy: 0.867188\n",
      "step: 3140, loss: 0.020322, accuracy: 0.875000\n",
      "step: 3150, loss: 0.018989, accuracy: 0.906250\n",
      "step: 3160, loss: 0.021085, accuracy: 0.890625\n",
      "step: 3170, loss: 0.024532, accuracy: 0.851562\n",
      "step: 3180, loss: 0.017824, accuracy: 0.917969\n",
      "step: 3190, loss: 0.021597, accuracy: 0.878906\n",
      "step: 3200, loss: 0.016433, accuracy: 0.902344\n",
      "step: 3210, loss: 0.021458, accuracy: 0.875000\n",
      "step: 3220, loss: 0.021842, accuracy: 0.867188\n",
      "step: 3230, loss: 0.021195, accuracy: 0.871094\n",
      "step: 3240, loss: 0.017582, accuracy: 0.917969\n",
      "step: 3250, loss: 0.016340, accuracy: 0.921875\n",
      "step: 3260, loss: 0.019079, accuracy: 0.886719\n",
      "step: 3270, loss: 0.017821, accuracy: 0.902344\n",
      "step: 3280, loss: 0.020748, accuracy: 0.871094\n",
      "step: 3290, loss: 0.019373, accuracy: 0.875000\n",
      "step: 3300, loss: 0.019170, accuracy: 0.890625\n",
      "step: 3310, loss: 0.017386, accuracy: 0.929688\n",
      "step: 3320, loss: 0.022532, accuracy: 0.863281\n",
      "step: 3330, loss: 0.021979, accuracy: 0.851562\n",
      "step: 3340, loss: 0.021972, accuracy: 0.886719\n",
      "step: 3350, loss: 0.016364, accuracy: 0.929688\n",
      "step: 3360, loss: 0.016813, accuracy: 0.933594\n",
      "step: 3370, loss: 0.022652, accuracy: 0.871094\n",
      "step: 3380, loss: 0.021046, accuracy: 0.871094\n",
      "step: 3390, loss: 0.025760, accuracy: 0.835938\n",
      "step: 3400, loss: 0.019289, accuracy: 0.890625\n",
      "step: 3410, loss: 0.020333, accuracy: 0.878906\n",
      "step: 3420, loss: 0.020274, accuracy: 0.875000\n",
      "step: 3430, loss: 0.018463, accuracy: 0.910156\n",
      "step: 3440, loss: 0.018442, accuracy: 0.902344\n",
      "step: 3450, loss: 0.018461, accuracy: 0.917969\n",
      "step: 3460, loss: 0.019866, accuracy: 0.878906\n",
      "step: 3470, loss: 0.024859, accuracy: 0.855469\n",
      "step: 3480, loss: 0.020727, accuracy: 0.882812\n",
      "step: 3490, loss: 0.019184, accuracy: 0.890625\n",
      "step: 3500, loss: 0.017129, accuracy: 0.894531\n",
      "step: 3510, loss: 0.018003, accuracy: 0.878906\n",
      "step: 3520, loss: 0.018601, accuracy: 0.894531\n",
      "step: 3530, loss: 0.019636, accuracy: 0.871094\n",
      "step: 3540, loss: 0.017261, accuracy: 0.914062\n",
      "step: 3550, loss: 0.023234, accuracy: 0.882812\n",
      "step: 3560, loss: 0.021839, accuracy: 0.867188\n",
      "step: 3570, loss: 0.016519, accuracy: 0.921875\n",
      "step: 3580, loss: 0.019951, accuracy: 0.878906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3590, loss: 0.018658, accuracy: 0.875000\n",
      "step: 3600, loss: 0.020578, accuracy: 0.886719\n",
      "step: 3610, loss: 0.020380, accuracy: 0.855469\n",
      "step: 3620, loss: 0.017532, accuracy: 0.906250\n",
      "step: 3630, loss: 0.019322, accuracy: 0.863281\n",
      "step: 3640, loss: 0.016876, accuracy: 0.917969\n",
      "step: 3650, loss: 0.019413, accuracy: 0.894531\n",
      "step: 3660, loss: 0.017087, accuracy: 0.914062\n",
      "step: 3670, loss: 0.016489, accuracy: 0.906250\n",
      "step: 3680, loss: 0.022068, accuracy: 0.875000\n",
      "step: 3690, loss: 0.021615, accuracy: 0.886719\n",
      "step: 3700, loss: 0.022469, accuracy: 0.851562\n",
      "step: 3710, loss: 0.019051, accuracy: 0.898438\n",
      "step: 3720, loss: 0.021807, accuracy: 0.863281\n",
      "step: 3730, loss: 0.017134, accuracy: 0.910156\n",
      "step: 3740, loss: 0.018900, accuracy: 0.902344\n",
      "step: 3750, loss: 0.016945, accuracy: 0.914062\n",
      "step: 3760, loss: 0.017612, accuracy: 0.890625\n",
      "step: 3770, loss: 0.015693, accuracy: 0.902344\n",
      "step: 3780, loss: 0.018700, accuracy: 0.894531\n",
      "step: 3790, loss: 0.018655, accuracy: 0.898438\n",
      "step: 3800, loss: 0.023510, accuracy: 0.863281\n",
      "step: 3810, loss: 0.019592, accuracy: 0.886719\n",
      "step: 3820, loss: 0.024500, accuracy: 0.851562\n",
      "step: 3830, loss: 0.019135, accuracy: 0.886719\n",
      "step: 3840, loss: 0.020391, accuracy: 0.878906\n",
      "step: 3850, loss: 0.025838, accuracy: 0.839844\n",
      "step: 3860, loss: 0.018896, accuracy: 0.902344\n",
      "step: 3870, loss: 0.018400, accuracy: 0.902344\n",
      "step: 3880, loss: 0.024336, accuracy: 0.828125\n",
      "step: 3890, loss: 0.019084, accuracy: 0.906250\n",
      "step: 3900, loss: 0.020125, accuracy: 0.886719\n",
      "step: 3910, loss: 0.020462, accuracy: 0.882812\n",
      "step: 3920, loss: 0.021758, accuracy: 0.855469\n",
      "step: 3930, loss: 0.021139, accuracy: 0.871094\n",
      "step: 3940, loss: 0.021454, accuracy: 0.871094\n",
      "step: 3950, loss: 0.021293, accuracy: 0.851562\n",
      "step: 3960, loss: 0.017760, accuracy: 0.906250\n",
      "step: 3970, loss: 0.017690, accuracy: 0.906250\n",
      "step: 3980, loss: 0.015349, accuracy: 0.914062\n",
      "step: 3990, loss: 0.017935, accuracy: 0.894531\n",
      "step: 4000, loss: 0.020307, accuracy: 0.867188\n",
      "step: 4010, loss: 0.018993, accuracy: 0.898438\n",
      "step: 4020, loss: 0.015157, accuracy: 0.925781\n",
      "step: 4030, loss: 0.015901, accuracy: 0.917969\n",
      "step: 4040, loss: 0.023563, accuracy: 0.847656\n",
      "step: 4050, loss: 0.021768, accuracy: 0.867188\n",
      "step: 4060, loss: 0.018205, accuracy: 0.910156\n",
      "step: 4070, loss: 0.020875, accuracy: 0.875000\n",
      "step: 4080, loss: 0.018955, accuracy: 0.898438\n",
      "step: 4090, loss: 0.016932, accuracy: 0.929688\n",
      "step: 4100, loss: 0.018409, accuracy: 0.894531\n",
      "step: 4110, loss: 0.020412, accuracy: 0.882812\n",
      "step: 4120, loss: 0.022206, accuracy: 0.859375\n",
      "step: 4130, loss: 0.020560, accuracy: 0.886719\n",
      "step: 4140, loss: 0.020762, accuracy: 0.875000\n",
      "step: 4150, loss: 0.017141, accuracy: 0.906250\n",
      "step: 4160, loss: 0.018053, accuracy: 0.894531\n",
      "step: 4170, loss: 0.017748, accuracy: 0.902344\n",
      "step: 4180, loss: 0.015939, accuracy: 0.917969\n",
      "step: 4190, loss: 0.017430, accuracy: 0.914062\n",
      "step: 4200, loss: 0.017189, accuracy: 0.890625\n",
      "step: 4210, loss: 0.021030, accuracy: 0.886719\n",
      "step: 4220, loss: 0.014291, accuracy: 0.937500\n",
      "step: 4230, loss: 0.014230, accuracy: 0.929688\n",
      "step: 4240, loss: 0.019235, accuracy: 0.886719\n",
      "step: 4250, loss: 0.018374, accuracy: 0.898438\n",
      "step: 4260, loss: 0.018330, accuracy: 0.917969\n",
      "step: 4270, loss: 0.020658, accuracy: 0.878906\n",
      "step: 4280, loss: 0.023710, accuracy: 0.855469\n",
      "step: 4290, loss: 0.015855, accuracy: 0.917969\n",
      "step: 4300, loss: 0.021229, accuracy: 0.855469\n",
      "step: 4310, loss: 0.020177, accuracy: 0.871094\n",
      "step: 4320, loss: 0.019037, accuracy: 0.882812\n",
      "step: 4330, loss: 0.023401, accuracy: 0.851562\n",
      "step: 4340, loss: 0.019796, accuracy: 0.882812\n",
      "step: 4350, loss: 0.021222, accuracy: 0.871094\n",
      "step: 4360, loss: 0.018911, accuracy: 0.894531\n",
      "step: 4370, loss: 0.021381, accuracy: 0.871094\n",
      "step: 4380, loss: 0.017926, accuracy: 0.886719\n",
      "step: 4390, loss: 0.020127, accuracy: 0.871094\n",
      "step: 4400, loss: 0.022285, accuracy: 0.839844\n",
      "step: 4410, loss: 0.019493, accuracy: 0.882812\n",
      "step: 4420, loss: 0.017921, accuracy: 0.902344\n",
      "step: 4430, loss: 0.016631, accuracy: 0.906250\n",
      "step: 4440, loss: 0.022435, accuracy: 0.855469\n",
      "step: 4450, loss: 0.017202, accuracy: 0.906250\n",
      "step: 4460, loss: 0.018853, accuracy: 0.886719\n",
      "step: 4470, loss: 0.019160, accuracy: 0.898438\n",
      "step: 4480, loss: 0.020519, accuracy: 0.878906\n",
      "step: 4490, loss: 0.020924, accuracy: 0.890625\n",
      "step: 4500, loss: 0.019762, accuracy: 0.882812\n",
      "step: 4510, loss: 0.019934, accuracy: 0.867188\n",
      "step: 4520, loss: 0.017302, accuracy: 0.902344\n",
      "step: 4530, loss: 0.018223, accuracy: 0.890625\n",
      "step: 4540, loss: 0.017217, accuracy: 0.917969\n",
      "step: 4550, loss: 0.021526, accuracy: 0.867188\n",
      "step: 4560, loss: 0.017858, accuracy: 0.894531\n",
      "step: 4570, loss: 0.018889, accuracy: 0.906250\n",
      "step: 4580, loss: 0.020742, accuracy: 0.890625\n",
      "step: 4590, loss: 0.018014, accuracy: 0.898438\n",
      "step: 4600, loss: 0.021484, accuracy: 0.859375\n",
      "step: 4610, loss: 0.021014, accuracy: 0.859375\n",
      "step: 4620, loss: 0.018788, accuracy: 0.878906\n",
      "step: 4630, loss: 0.017697, accuracy: 0.921875\n",
      "step: 4640, loss: 0.019780, accuracy: 0.875000\n",
      "step: 4650, loss: 0.019199, accuracy: 0.886719\n",
      "step: 4660, loss: 0.016410, accuracy: 0.902344\n",
      "step: 4670, loss: 0.016687, accuracy: 0.906250\n",
      "step: 4680, loss: 0.017235, accuracy: 0.894531\n",
      "step: 4690, loss: 0.020788, accuracy: 0.878906\n",
      "step: 4700, loss: 0.017112, accuracy: 0.906250\n",
      "step: 4710, loss: 0.019071, accuracy: 0.894531\n",
      "step: 4720, loss: 0.020494, accuracy: 0.875000\n",
      "step: 4730, loss: 0.019966, accuracy: 0.882812\n",
      "step: 4740, loss: 0.020079, accuracy: 0.875000\n",
      "step: 4750, loss: 0.021179, accuracy: 0.863281\n",
      "step: 4760, loss: 0.015837, accuracy: 0.906250\n",
      "step: 4770, loss: 0.015620, accuracy: 0.917969\n",
      "step: 4780, loss: 0.014663, accuracy: 0.929688\n",
      "step: 4790, loss: 0.021083, accuracy: 0.882812\n",
      "step: 4800, loss: 0.019557, accuracy: 0.878906\n",
      "step: 4810, loss: 0.020955, accuracy: 0.878906\n",
      "step: 4820, loss: 0.019235, accuracy: 0.875000\n",
      "step: 4830, loss: 0.020823, accuracy: 0.875000\n",
      "step: 4840, loss: 0.018410, accuracy: 0.902344\n",
      "step: 4850, loss: 0.020603, accuracy: 0.878906\n",
      "step: 4860, loss: 0.015702, accuracy: 0.910156\n",
      "step: 4870, loss: 0.017895, accuracy: 0.890625\n",
      "step: 4880, loss: 0.017929, accuracy: 0.910156\n",
      "step: 4890, loss: 0.019352, accuracy: 0.886719\n",
      "step: 4900, loss: 0.016820, accuracy: 0.910156\n",
      "step: 4910, loss: 0.018770, accuracy: 0.886719\n",
      "step: 4920, loss: 0.016170, accuracy: 0.917969\n",
      "step: 4930, loss: 0.015850, accuracy: 0.925781\n",
      "step: 4940, loss: 0.016601, accuracy: 0.902344\n",
      "step: 4950, loss: 0.017642, accuracy: 0.886719\n",
      "step: 4960, loss: 0.020538, accuracy: 0.886719\n",
      "step: 4970, loss: 0.018077, accuracy: 0.906250\n",
      "step: 4980, loss: 0.016123, accuracy: 0.921875\n",
      "step: 4990, loss: 0.017277, accuracy: 0.902344\n",
      "step: 5000, loss: 0.020094, accuracy: 0.863281\n"
     ]
    }
   ],
   "source": [
    "lossac = []\n",
    "for step, (batchX, batchY) in enumerate(trainData.take(steps),1):\n",
    "    loss, pred = runOptimization(batchX, batchY)\n",
    "    if step % iStep == 0:\n",
    "        # pred = network(batchX)\n",
    "        # loss = crossEntropy(pred, batchY)\n",
    "        acc = accuracy(pred, batchY)\n",
    "        print(\"step: %i, loss: %f, accuracy: %f\" %(step,loss,acc))\n",
    "        lossac.append(loss)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "NYO0luQquYbs",
    "outputId": "a6553bac-98cf-448e-c401-f0ca2b64f517"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5e60057610>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMUZx0nt_5Up"
   },
   "source": [
    "# Test (Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "AiquYfkYXy-C"
   },
   "outputs": [],
   "source": [
    "predY = network(xTest)\n",
    "classLabel = tf.argmax(predY, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iByCREKD_9_K"
   },
   "source": [
    "# Reshape the flatten images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UZI9dAq7bPPo"
   },
   "outputs": [],
   "source": [
    "xTestImg = np.reshape(xTest, [-1,28,28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "fa6euDWyb_V3",
    "outputId": "dcba2562-9c0e-44e1-e861-3134e66c392d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArcAAALICAYAAABl6dhjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABq00lEQVR4nO3dd7hU1fX/8bXoVbpIV8DeaBGMKCrEIIiiFGskiYqaRBD5oqj4A3tXxI5CFDSgFEFFEXsQJAQMWCMaqSJKlxbq/v0x1++Xtb3OMP3Mvu/X8/A8fGTmzDqwPXfdc9fsUeecAAAAACEole8CAAAAgEyhuQUAAEAwaG4BAAAQDJpbAAAABIPmFgAAAMGguQUAAEAwSkRzq6rvqeqluX4uChvrBqlg3SBZrBmkgnXzywqquVXVJaraKd91/BJVPUpV31DVNarKBsIRUQDr5glV3bzXr+2quinfdZV0BbBuuN5ETAGsmT6qOl9Vf1TVFap6j6qWyXddJV3U183eVPUdVXVRXzcF1dwWgJ0i8qKIXJLvQlA4nHNXOOeq/PRLRMaJyIR814XI43qDZFUSkatFpLaItBWRjiLyP/ksCIVDVS8UkUg3tT8JorlV1Rqq+qqqrlbV9UW/b+g9rJmqzlXVjao6VVVr7vX8dqo6W1U3qOpCVT05lTqcc18650aJyGepnw1yJSrrxqupsoj0EJFn0z0WsiMq64brTeGI0Jp53Dk30zm3wzn3rYg8LyInpHxiyKqorJuiY1UTkaEicm2qx8ilIJpbiZ3HX0WkiYg0FpFtIvKI95iLReSPIlJfRHaJyAgREVVtICLTROQ2Eakpse9iJ6lqHf9FVLVx0SJpnKXzQG5Fcd30EJHVIvL3VE4IORHFdYNoi+qaOUn45ijKorRu7hCRx0VkVTonlCtBNLfOubXOuUnOua3OuU0icruIdPAeNtY596lzbouI3CQivVW1tIhcJCKvOedec87tcc69KSLzRKRLMa+zzDlX3Tm3LMunhByI6LrpIyJjnHPMUEZURNcNIiyKa0ZV/yAibUTkvjRPD1kSlXWjqm0kdof/4QyeXlYVxOxEIqpaSUQeFJHOIlKj6D9XVdXSzrndRXn5Xk9ZKiJlJTZ31EREeqlqt73+vKyIvJvdqpFvUVs3qtpIYheuy1I9BrIvausG0Re1NaOq3UXkLhHp5Jxbk+pxkF1RWDeqWkpEHhOR/s65Xaqa/InkQRDNrYgMFJFDRaStc26VqrYQkX+JyN7/Co32+n1jib0ZY43EFsZY5xwNRckTtXVzsYjMds59k8FjIvOitm4QfZFZM6raWUSeEpGuzrlPMnFMZE0U1s1+ErvD/0JRY1u66L+vUNVezrmZaR4/KwpxLKGsqlbY61cZEakqsVmUDUXD1EOLed5FqnpE0XdCt4jIxKLvfJ4TkW6q+ltVLV10zJOLGdpOSGMqiEi5olxBVcuneqLIqMium71cLCLPpPF8ZF5k1w3Xm8iK8po5VWJvIuvhnJub8hkiG6K6bjZKbJ63RdGvn8YaWovIP5I9yVwpxOb2NYn9Y//0a5iIDBeRihL7bmWOiEwv5nljJdY4rBKRCiLST0TEObdcRM4SkRsk9kae5SIySIr5uykaut4cZ+i6SVFNPw3obxORL5M7PWRJlNeNqOrxItJQ2AIsaqK8brjeRFOU18xNIlJNRF7T/9tX+/VUThIZF8l142JW/fSr6FgiIt8753akeK5Zp7xvBQAAAKEoxDu3AAAAQLFobgEAABAMmlsAAAAEg+YWAAAAwUhqn1tV5d1nBcw5l/Pdl1kzBW+Nc+5nH9eYbaybwsa1BingWoNUFLtuuHMLIJ6l+S4AQInAtQapKHbdJLxzq6p9RaRvxstBsFgzSAXrBslizSAVrJvwJbXPLbfvCxs/KkQK5jvn2uT6RVk3hY1rDVLAtQapKHbdMJYAAACAYNDcAgAAIBg0twAAAAgGzS0AAACCQXMLAACAYNDcAgAAIBg0twAAAAgGzS0AAACCQXMLAACAYNDcAgAAIBg0twAAAAgGzS0AAACCUSbfBQBA6N5++22Ta9SoYXKrVq1yWQ4ABI07twAAAAgGzS0AAACCQXMLAACAYDBzG8f7779vsnPO5JNPPjmH1QAoVP6149hjjzW5cePGJi9btizrNQHIv1Kl7D3Ggw46yOSlS5eavGvXrrReb+LEiSb78/5nn322yQsXLkzr9fKFO7cAAAAIBs0tAAAAgkFzCwAAgGAwc7uXZs2amdyyZUuT165dm8tysA/Kly9vsj8n3bZt26SO589Grlq1yuSnn37a5L/97W8m/+c//zF5586dSb0+SiZ/zu2hhx7KUyVIVcWKFU0+9NBDTe7UqZPJ/rXC//rjz14uXrzY5JdfftnkRYsW7XuxiIyDDz7Y5M8//9zkuXPnmty1a1eT161bl9brN2nSxORLLrnE5H79+qV1/Hzhzi0AAACCQXMLAACAYNDcAgAAIBjM3O7l8MMPN7lq1aomM3MbPWXLljW5RYsWJu/Zsyet49etW9fkG2+8MW729yTs0qWLyV999ZXJu3fvTqs+hKFSpUr5LgFJuu6660y+4IILTD766KNN9uf5X331VZNr1Khhsj9je+KJJ5p8yy23mDxs2DCT77nnnmKqRtScccYZcf/8uOOOM7lPnz4mP/jggxmtx19nhYo7twAAAAgGzS0AAACCQXMLAACAYJTomdvKlSub/Nhjj5mcaEYK+bd582aT7733XpMHDhxosr8vbqb5ewZ+9tlnJvvzTLNnz85qPSgMDRs2zHcJ8NSqVcvkN954w+RWrVqZPGHCBJP9vYu/+eabDFYn0qtXL5P9/Ulr1qxp8tChQ03evn17RutBYfD31fXVrl07R5VkF3duAQAAEAyaWwAAAASD5hYAAADBKNEzt1dddZXJiebeJk6cmM1ykAE33XSTyW+++abJRx55pMlnnnmmySeddJLJFSpUyGB1Itdcc43JzNxCRGTRokX5LgGeO+64w+RDDz3U5NGjR5v8pz/9yeQdO3Zkp7Ai/oyvn2fMmGGyX++ll15q8rZt2zJYHfbVypUrk3r8d999l9br+XvDh4o7twAAAAgGzS0AAACCQXMLAACAYAQ9c6uqJvszRv5MVSJr165Nuybk1t///ve4+fHHHzf54YcfNrlr165xj+/P5NatWzfu4/29MevXr29ysvNXiKZSpex9g9KlS+epEqSqZ8+eJg8fPtxkf74/anr06GGyv+f20UcfbfLcuXOzXhN+zv8akIi/P3+yPv/8c5P9WfJQcOcWAAAAwUh451ZV+4pI3xzUgkCwZpAK1g2SxZpBKlg34UvY3DrnRorISBERVXUJHg6wZpAS1g2SxZpBKlg34Qt65tafJXnyySfjPn7ZsmUmN27cOOM1Idr8vY/97OvQoYPJ77zzTtzHN2nSxOQaNWqYzMxtGI444giT/f2TfR07djT5oYceynhNSI7//+aGDRvyU0iKNm3aZPL48eNN9mdymbktDG+//XZaz/dnrX3r169P6/hRwcwtAAAAgkFzCwAAgGDQ3AIAACAYQc3ctmjRwuR58+bFffzhhx9u8qxZszJdEoASaMmSJSYvWLDAZP9adeSRR2a3ICTt+uuvN/ndd9/NUyWZ4e/7jsK0//77m+xfa3z+Xu0HH3ywyc7Z99O99957SdXTrl07kxcuXGjytm3bkjpepnDnFgAAAMGguQUAAEAwaG4BAAAQjIKeufX3knz55ZdN3r17t8mtWrUyedGiRSb7M0lffPFF3AwAxdm8ebPJoewdWZLcfffd+S4ho/zZSj8jPz766KOkHu/vcztlyhST//vf/5p84IEHJnX8Sy+91OQLL7ww7uOrVq1q8iGHHGJyopngbOHOLQAAAIJBcwsAAIBg0NwCAAAgGAU1c9ugQQOTX3/9dZP9zwK/6KKLTP74449N7t69u8nVqlUz+c477zTZn+HNtN/85jcmlylj/3n880Xh89f0Z599lqdKkEnlypUzuWLFiib78/3sQQqf//Vo165dJleoUMFkf87bd+aZZ5p81113pVEdMuXzzz83ecOGDSZXr17d5EqVKpl8wQUXZLSe8uXLx83//ve/Tf7Tn/5k8tKlSzNaT6q4cwsAAIBg0NwCAAAgGDS3AAAACEZBzdz+4Q9/MLlRo0Ym33zzzSZPmDAh7vGGDBli8s6dO00eN25csiXG1bt3b5ObNWtmcqdOnUweO3ZsRl+/JDjqqKNMfuCBB7L6ev6cd7KeeeYZkz/99NOknn/NNdek9Xxkh7/Xo//56+w5Cl/Tpk1NfvbZZ02uXbu2yfXq1TP5q6++Mnnx4sUm+7OQkyZNSqlOZNb3339v8kEHHWRy//79TfavLV27djXZn5H1Z7P9+X7/2vPkk0+a7H9+wPTp06UQcOcWAAAAwaC5BQAAQDBobgEAABCMgpq59WdJfH379jX5tNNOi/v4Vq1ambxp0yaT/X1yt2zZYrK/L60/E+XzZ2X8z5u/7777TE40M4yf8/cG7tixY54q2Td169aNmxPx59AHDhyYdk3IPfY3Dl/jxo1N9mdeW7dubbL/HhJ/39suXbrEfX6bNm1Mvv/++032v94hGn788UeTb7311rSO5/ct/p7bP/zwg8n+vrWFiju3AAAACAbNLQAAAIJBcwsAAIBgFNTM7b333mvywoULTT7jjDNM9uctGzRoEPf4/ixKolmXL7/80uQqVaqY/P7775t8yimnmLxjx464x0fy/NnFyZMnm3zOOefkspyM8/eqfOqpp/JUCTLp7bffzncJyLJBgwaZfPTRR5v80ksvmezP3Pr8Wcorr7zS5OXLl8f981Kl7L0tf89sFKa2bduaXK5cubiPf+WVV7JZTt5w5xYAAADBoLkFAABAMGhuAQAAEIyCmrn193+bOHFi3OzP0PozSq+++qrJPXv2NJmZ2MKzc+dOk/05sttvv91kf67a3zvSn6s+9NBD06rvscceM3nUqFFJPX/t2rUm+3N1KEydO3c2+aGHHspTJciUAw880OSLL77Y5HXr1pnco0cPk/193f2vT7179zbZv3bNnTvXZP89KXfeeafJ/vsTLrnkEpP9fdkRTe3atTPZn632bd26NZvl5A13bgEAABAMmlsAAAAEg+YWAAAAwSiomdtk9e/fP+6fP/LIIyYzYxsefybVz9OnTzd5zJgxJvt7Fft7Jz/33HNJ1ePP2C5YsCCp56MwfPPNNybPnz/f5NatW5t88sknm9y+fXuTP/jgg8wVh5zYtGmTyf77ASpUqGDyCSecYLL/9cuf4e3UqZPJiebv/feY1K1b1+Q+ffqY/Ne//tXkp59+Ou7xkB/HHXecyTfeeGPcx+/atctk/30goeDOLQAAAIJBcwsAAIBg0NwCAAAgGEHP3PozSb533nknR5Ugqh599NGkHn/66adnqRKExN878p577jF5/PjxJvt7ml577bUmM3NbePw9qS+77DKTJ02aZPLMmTNNvvnmm032Z2K3bduWVn3+/L+f/bnvyy+/3OQyZWz7MGXKlLTqQWq6d+9ucq1ateI+3p/9XrRoUaZLigTu3AIAACAYCe/cqmpfEembg1oQCNYMUsG6QbJYM0gF6yZ8CZtb59xIERkpIqKqLusVoeCxZpAK1g2SxZpBKlg34Qtq5rZKlSomN23a1OTXX3/d5N27d2e9JoSlRo0a+S4BBWjixIkmL1261GT/WlWxYsWs14Tc8veFrVevXtzHf//999ksJyF/zttfs4MGDTL52GOPNdmfGUZ2/PrXv07q8f6e2/7XtPXr16ddUxQwcwsAAIBg0NwCAAAgGDS3AAAACEZQM7eVK1c22f8s7ltvvdVk55gjR3zHHHOMyR07dsxTJQgZ16Lw+fuL5numNlnLly83uV+/fnmqpGSrVq2ayUceeWRSz/f3L/b/HUOZlebOLQAAAIJBcwsAAIBg0NwCAAAgGEHN3Pr8fWz/9a9/5akSFKp169aZ/N1335nsz3UD++Lqq682eezYsSZPnjw5h9UAKBQVKlQwefXq1SbXrFkz7vOnTJli8ujRozNSV9Rw5xYAAADBoLkFAABAMGhuAQAAEIygZm4POOAAk/3Pxl6wYEEOq0EIVqxYYfLnn39ucqKZ22HDhpn8ySefZKIsFLhXXnnF5OrVq+enEAAFxd8feeDAgSbfcMMNJv/www8m9+7d22T/vUmh4M4tAAAAgkFzCwAAgGDQ3AIAACAYmsxnmqsqH4BewJxzmuvXDG3NDB482OQjjjjCZP9zuRcvXmzynj17slNY9sx3zrXJ9YuGtm5KGq41SAHXGqSi2HXDnVsAAAAEg+YWAAAAwaC5BQAAQDCYuS1BmINDCpiDQ9K41iAFXGuQCmZuAQAAEDaaWwAAAASD5hYAAADBoLkFAABAMGhuAQAAEAyaWwAAAASD5hYAAADBKJPk49eIyFIRqV30+6iKcn35qq1JHl5ThDWTKaybaKK+n2PNxEd9xWPdxEd9xSt23ST1IQ7/+yTVefnYbHlfRbm+KNeWTVE/b+qLpqifN/VFT9TPmfqiKernTX3JYSwBAAAAwaC5BQAAQDBSbW5HZrSKzItyfVGuLZuift7UF01RP2/qi56onzP1RVPUz5v6kpDSzC0AAAAQRYwlAAAAIBg0twAAAAgGzS0AAACCQXMLAACAYNDcAgAAIBg0twAAAAgGzS0AAACCQXMLAACAYNDcAgAAIBglorlV1fdU9dJcPxeFjXWDVLBukCzWDFLBuvllBdXcquoSVe2U7zriUdUBqrpKVTeq6mhVLZ/vmkq6qK8bVe2jqvNV9UdVXaGq96hqmXzXVdIVwLopr6oPqupKVV2vqo+patl811WSRX3N7E1V31FVx7Um/6K+blT1PFX9sqiv+UFVn1XV/fJdVzwF1dxGnar+VkQGi0hHETlQRJqKyM35rAkFoZKIXC0itUWkrcTWz//ksyAUhMEi0kZEjhKRQ0SklYgMyWtFKAiqeqGI0NRiX80SkROcc9Uk1teUEZHb8ltSfEE0t6paQ1VfVdXVRXcwXlXVht7Dmqnq3KLvPKaqas29nt9OVWer6gZVXaiqJ6dYSh8RGeWc+8w5t15EbhWR36d4LGRZVNaNc+5x59xM59wO59y3IvK8iJyQ8okhq6KybkSkm4iMcM6tc86tFpERIvLHFI+FLIrQmhFVrSYiQ0Xk2lSPgdyIyrpxzi13zq3Z6z/tFpHmqRwrV4JobiV2Hn8VkSYi0lhEtonII95jLpbYhb++iOyS2BcCUdUGIjJNYt+F1JTYHbNJqlrHfxFVbVy0SBr/Qh1HisjCvfJCEamrqrVSPC9kV1TWje8kEfks6bNBrkRl3WjRr71zw6LmBdESlTUjInKHiDwuIqvSOSHkRGTWjaq2V9WNIrJJRHqIyPC0zizLgmhunXNrnXOTnHNbnXObROR2EengPWysc+5T59wWEblJRHqramkRuUhEXnPOveac2+Oce1NE5olIl2JeZ5lzrrpzbtkvlFJFRDbulX/6fdU0Tg9ZEqF1879U9Q8S+1HzfWmeHrIkQuvmdRHpr6p1VPUAEelX9N8rZeA0kUFRWTOq2kZiPxV6OIOnhyyJyropeswHRWMJDUXkXhFZkpGTzJIgmltVraSqT6rqUlX9UUT+LiLVi/6Bf7J8r98vFZGyEptxbCIivYq+a9mgqhtEpL2I1EuhlM0isveQ9U+/35TCsZBlEVo3P9XTXUTuEpHTvR8BIUIitG5uF5F/icgCEZktIlNEZKeI/JDCsZBFUVgzqlpKRB4Tkf7OuV1pnA5yJArrxlc0OjddRManc5xsC6K5FZGBInKoiLR1zu0nsR/ritgf2TXa6/eNJfZFYI3EFsbYou9afvpV2Tl3Vwp1fCYix+6VjxWR751za1M4FrIvKutGVLWziDwlIt2cc5+kcgzkTCTWjXNum3PuL865Bs65piKyVkTmO+d2p3JSyKoorJn9JPZToRdUdZWI/LPov69Q1ROTPBZyIwrrpjhlRKRZBo6TNYXY3JZV1Qp7/SojsR/7bxORDUXD1EOLed5FqnqEqlYSkVtEZGLRF4HnRKSbqv5WVUsXHfPkYoa298UYEbmk6HVqSOydy8+kcpLIuMiuG1U9VWJvIuvhnJub8hkiG6K8bhqoan2NaSexH0kWVwtyK6prZqPE5jJbFP366cfTrUXkH8meJDIuqutGVPVCjc3lqqo2kdhPjd5O+UxzoBCb29ck9o/9069hEhtsriix71bmSOyWuW+sxBrNVSJSQYrm05xzy0XkLBG5QURWS+y7nUFSzN9N0T/uZv2FoWvn3HQRuUdE3pXYjweWCl9soiKy60ZiTUk1EXmt6HGbVfX1VE4SGRflddNMYuMIW0TkWREZ7JybkfwpIsMiuWZczKqffhUdSyT208UdKZ4rMieS66bIERK71myW2LZgX4rIZUmfYQ6pcy7fNQAAAAAZUYh3bgEAAIBi0dwCAAAgGDS3AAAACAbNLQAAAIJRJpkHqyrvPitgzjlN/KjMYs0UvDXOuZ99XGO2sW4KG9capIBrDVJR7Lrhzi2AeJbmuwAAJQLXGqSi2HWT8M6tqvYVkb4ZLwfBYs0gFawbJIs1g1SwbsKX1D633L4vbPyoECmY75xrk+sXZd0UNq41SAHXGqSi2HXDWAIAAACCQXMLAACAYNDcAgAAIBg0twAAAAgGzS0AAACCQXMLAACAYNDcAgAAIBg0twAAAAhGwk8oA0qSWrVqmXznnXeafNlll5n8/vvvmzxkyBCTP/jggwxWBwAAEuHOLQAAAIJBcwsAAIBg0NwCAAAgGOqc2/cHq+77gxE5zjnN9WtGfc2UL1/e5GnTppl8yimnxH2+qv0rXbt2rcl33HGHyQ8++GCyJebbfOdcm1y/aNTXDeLjWoMUBHmtOeqoo0weMGCAyT179jS5atWqSR3f/xq0ZMkSk6+77jqTJ02aZPLu3buTer0IKnbdcOcWAAAAwaC5BQAAQDBobgEAABCMgpq5PfLII03++OOPc/r6pUrZ7wU2bdpk8i233GLyk08+afK2bdtM3rVrVwarS4w5uJ8bNGiQyXfddVfcx7/66qsmd+vWzWT//6d169aZfPbZZ5tcAPvgBjkHh+ziWhN9FSpUMPmxxx4zuXnz5iafdNJJ2S4piGtNtWrVTJ43b57J/vsy/Pdh/Pjjj3GP37p1a5ObNGli8nnnnWdy5cqVTX7jjTdM9r+G5bovyQBmbgEAABA2mlsAAAAEg+YWAAAAwYj0zG39+vVN9mdFDj/88Ky+/vfffx/3z/396CpVqhT38a+88orJ/vk88cQTSVSXPObgfu7+++83+eqrrzb51ltvjZsvu+wykx999NG4r7d582aT/fmsCApiDi7fGjVqZPIJJ5xgsj/PePDBB5vcqVMnk7t06WLy66+/nm6JGcW1JnpOP/10kwcPHmyyvya/+OILk48++ujsFPZ/grjWjBo1yuTly5eb7H/N8d+7ky6/b5o1a5bJ/ozur3/9a5PnzJmT0XpygJlbAAAAhI3mFgAAAMGguQUAAEAwyuS7gL35+8jecccdJvszttu3bzfZn2157rnnTPb3GD322GNNfuutt0z293/buXOnyW3bto1bX/fu3U3u2LGjya1atTL5V7/6lcnXX3+9yT/88IMgs/w9Bf09Cf29iv3P4fbnpE899VST0/3ccBSGAw44wOTOnTub7O+fXKdOnaSOv2fPHpOTea8EcuPKK680+YorrjDZn4v2Z16z7cwzzzTZn7H13X777dksJ1jXXnutyf6+ttm2atUqkxcvXmyyP3MbKu7cAgAAIBg0twAAAAgGzS0AAACCEal9bv15xPXr15vsz9hed911Jj/yyCNxj/+b3/zG5ClTppg8cuRIkwcMGBD3eMlq3769yTfffLPJHTp0MPmee+4xeejQoSb7M8CJsPdk9vXp08fk0aNHx3186dKls1lOJgSx92QiVapUMdnf47N69epxn+//O5YvX97kRO8PeOqpp0w+5phjTL7wwgtNvu2220z2rw35VhKuNb///e9Nfvrpp+M+fty4cSb/7ne/y3RJRsWKFU1euXKlyYnm/+vVq2fy6tWrM1PYLysR15ps23///U32Z3DXrFlj8kEHHWTyli1bslNY9rDPLQAAAMJGcwsAAIBg0NwCAAAgGJHa57Z3795x/9yfU0s0Y+t78803TV6xYkVSz0/XBx98YPJ5551n8vjx403298vzZ2dGjBiRweqQCV9++WW+S0AKKlWqZLK/p7T/ee2+uXPnmuzvafraa6+Z7O+n7Hv++efj/rk/I4zcK1MmuS+ftWvXNrls2bImJ/seikTGjBljMntslwyJ5u/vu+8+kwtwxnafcOcWAAAAwaC5BQAAQDBobgEAABCMSM3cdurUKe6fP/fccxl9vb///e8mjxo1KqPHT8TfN/Dcc881ef78+SYPGjTIZH9vzG3btmWwOqSiTZucb9OIDPBnbE866SST/T1DfZs2bTLZ39c2EX/+0t97cvfu3Sa/+uqrSR0f+XfIIYeY7K+pdGdu/WtP586dk3q+/x6WDRs2pFUPcqNHjx4mX3nllSYvXrzY5IcffjjrNUUBd24BAAAQjIR3blW1r4j0zUEtCARrBqlg3SBZrBmkgnUTvoTNrXNupIiMFAnvY+qQHawZpIJ1g2SxZpAK1k34IjVz6+9z65xdc7/5zW9M9j9fPVmXXXZZWs/PNP8znxcsWGBy165dTfbrZ9/b/PNnNVXV5Pfffz+X5SBF/t6P2d4L8uCDDza5bdu2Js+cOdPkd999N6v1IPP++c9/muzPaSerVCk7Vejvi55oTvyjjz4y2X9PR6b33UVmnHLKKSb7++P7/64dO3Y0uaS8N4eZWwAAAASD5hYAAADBoLkFAABAMCI1c5vIlClT8l1CTvnn68/c+rM0zNzmXq1atUxu166dyf7c+C233JL1mlB4/M97973++us5qgTZ0rNnT5Ovuuoqk/19zxNp1aqVyeecc05Sz/dnapmxLQy1a9c22X9fh/9enY0bN2a7pEjizi0AAACCQXMLAACAYNDcAgAAIBgFNXO7fv36fJcQKf4MLnJvxowZJjdo0MDkd955x+RZs2ZlvSYUHn9+3vfdd9/lqBLsq9dee83k7du3m1y+fPm4zx87dqzJnTt3jvv4pk2bmjxp0qREJRo7duww+ZFHHknq+YiGCRMmmHz22Web/Mc//tFk/9/9T3/6U3YKixju3AIAACAYNLcAAAAIBs0tAAAAglFQM7dAvj3++OMmt2zZ0mR/X9u33nrLZH/+CWEqXbp03HzYYYeZXKpU/PsMS5cuNblcuXIm++uOPUuzb+XKlSbv3r07qef7c9b/+Mc/TPb3xe3WrZvJDRs2NNlfA77hw4ebPG7cuH0pExF3wQUXmOzP5/fv39/kZs2amfzYY4+ZPHXq1AxWlz/cuQUAAEAwaG4BAAAQDJpbAAAABCNSM7f+3NmePXvyVEk0+HN1/mdI33HHHbksp0Tw96b09wy8/PLLTfbX6FlnnWXytGnTMlgd8qV58+Ym//nPfza5atWqJh9xxBEmt23bNq3X9/dL3rBhg8nPPvusyddcc01ar4fknXPOOSZPnjzZ5MqVK5vsX8/btGlj8pIlS+K+XqKvl5s2bTL55Zdfjns8hGHgwIEm+/shP/PMMyY/99xzJo8cOdLkBx54wORvv/02zQpzgzu3AAAACAbNLQAAAIJBcwsAAIBgRGrm1p8ZSrRvX+j8uTn/72Pr1q25LKdEGDJkiMk33HCDyf6/wS233GIyM7ZhqFOnjslz5841uVq1arksR959912Tr7jiCpO//vrrXJaDYvh7Wvv7h/7P//xPRl8v0dfL+++/3+Q5c+Zk9PVRGGbPnm3y0UcfbfKYMWNMHjBggMmXXnqpyf5s+dtvv51uiVnBnVsAAAAEg+YWAAAAwaC5BQAAQDA0mblWVc3qEOyaNWtMrl69usn+voG9e/fOZjk55+9z+Oabb5rsf3Z548aNTU40g+uc07gPyIJsr5l0Pfzwwyafd955JtesWdPkV1991WR/X9sAzXfOtUn8sMzK97qpUqWKyf/v//0/k08//fSkjlexYkWTDzrooLiP79Spk8nvv/++yVHfA5xrjUilSpVM/u1vf2vy4MGDTW7dunVSx/f3yfW/lrdo0cLkTz/9NKnj50GJvNbkW4UKFUweNmyYyVdffbXJK1euNPnUU081OdH+zFlQ7Lrhzi0AAACCQXMLAACAYNDcAgAAIBiRmrnt16+fyf5nGi9fvtzkli1bmux/3nrU7bfffib7n/l85plnmnzTTTeZfOeddyb1eszB/Xyu7Z///KfJ/v8P/oytv8efPwedbX79Z5xxhsmXXHKJyd27dzf5o48+SvYlmYPLAH+e/h//+IfJS5cuNdm/tm3cuDE7hWUJ15rEypYta7I/l+3vmX388ceb7M/cvvbaayb77weI+py2cK2JpL/85S8mjxgxwuR33nnHZP/9AjnAzC0AAADCRnMLAACAYNDcAgAAIBhl8l3A3vzP4j7llFNM7tatm8kjR440udD2vfX3VPVnbEePHm2yP4OMnytfvrzJ/j62/udk+3Not9xyS9ycSK1atUz297ps1aqVyR06dDD5gAMOMNlfI5s3bzZ56tSpJvvzTosWLUpQMXKhatWqcf98y5YtJhfajC2St3PnTpNPPvlkk/0Z20T8r4cFMGOLAvDtt9/mu4SUcOcWAAAAwaC5BQAAQDBobgEAABCMSM3c7tq1y+T33nvPZH/m1v+s7vPPP9/kcePGZa64FPif7d2/f3+T/X0Iv/vuO5OHDh1q8vbt2zNXXKCGDBlisr/vq7+P7Zo1a0yeMWOGyX369DG5S5cuJvt7TbZr187kBg0axK3Xn7ubP3++yc8++6zJw4cPN3nhwoVxj49ouPDCC+P+ub9HKcJXpoz98nvdddcl9Xx/TrtQZyORW+XKlTPZf9+H/3kDp512WtzjffXVV5kpLMO4cwsAAIBgJLxzq6p9RaRvDmpBIFgzSAXrBslizSAVrJvwJWxunXMjRWSkCB9Th33DmkEqWDdIFmsGqWDdhC9SM7c+f9/bunXrmnzttdea/MQTT8Q9XqZncP2Z2uOOO87kO++80+Rq1aqZPGvWLJP9+U5/BheJHXLIIUk9fv/99zfZ/zdJxJ+59Z8/e/Zsk59++mmT161bZ/JHH32U1OsjDCtWrMh3CcixChUqmOzvc5uI/34Bf09rf89v3rMRDZUrVza5Tp06Ji9ZsiSt4x911FEm9+rVy+TLL7/cZP9roG/Tpk0mX3HFFSaPGTMm2RJzgplbAAAABIPmFgAAAMGguQUAAEAw1N/3M+6D8zx47e/PNmzYMJP9GdytW7ea7M+wfvzxxyYn2mvy+uuvN7lWrVom+zO1vtGjR5vs72Ob7Rlb55wmflRm5XrN+PNGd9xxh8n16tUz+e9//7vJ/r+BP8eWaCZ27dq1Jm/bti3u4wvAfOdcm1y/aL6vNeny9zD111GTJk1MPvzww+M+vtCUhGtNuqpUqWLyhg0bknq+P+/vfy3/8MMPTT711FNN9vfYjoASca0ZP368yc2aNTM50d7l/nuPTjjhBJP9md6yZcvGPZ7/PpHJkyeb/MILL5i8cuXKuMfLg2LXDXduAQAAEAyaWwAAAASD5hYAAADBiPQ+t74dO3aY7M+srlq1yuRBgwaZ7M+2+Pnss8+O+/qJZpwmTJhg8tVXX22yP1PFvoOZ9+mnn5p85pln5qkSlGT+Htj+jK1v8eLFWawGJdG0adNMjuCMbYn0+eefm9y7d2+TW7dundTx5s6da7K/Z7Y/U+vvozt16lST9+zZk9TrRxV3bgEAABAMmlsAAAAEg+YWAAAAwSiofW6T5e95eu6552b0+G+99ZbJs2fPNjlqM07sPYkUlIi9JzOtX79+Jj/44INxH1+hQgWTo3btSBbXmsTKly9vsj87WalSJZNfeeUVk5999lmTa9asabI/a+m/ZyWCuNYgFexzCwAAgLDR3AIAACAYNLcAAAAIRkHtc5ssf89TPwNANnz22Wdx//z22283edeuXdksBxHk73N+7LHH5qkSIDzcuQUAAEAwaG4BAAAQDJpbAAAABCPomVsAyIe3337b5NKlS+epEgAoebhzCwAAgGDQ3AIAACAYNLcAAAAIBs0tAAAAgkFzCwAAgGDQ3AIAACAYNLcAAAAIRrL73K4RkaUiUrvo91EV5fryVVuTPLymCGsmU1g30UR9P8eaiY/6ise6iY/6ilfsulHnXNJHUtV5zrk2aZeUJVGuL8q1ZVPUz5v6oinq50190RP1c6a+aIr6eVNfchhLAAAAQDBobgEAABCMVJvbkRmtIvOiXF+Ua8umqJ839UVT1M+b+qIn6udMfdEU9fOmviSkNHMLAAAARBFjCQAAAAgGzS0AAACCQXMLAACAYNDcAgAAIBg0twAAAAgGzS0AAACCQXMLAACAYNDcAgAAIBg0twAAAAhGiWhuVfU9Vb00189FYWPdIBWsGySLNYNUsG5+WUE1t6q6RFU75buOX6Kq56nql6q6UVV/UNVnVXW/fNdV0kV93YiIqOoAVV1VtHZGq2r5fNdU0rFukKyorxlV/b2q7lbVzXv9OjnfdZV0BbBujlLVN1R1jaq6fNezLwqquS0As0TkBOdcNRFpKiJlROS2/JaEqFPV34rIYBHpKCIHSmzt3JzPmhB9rBuk6EPnXJW9fr2X74IQeTtF5EURuSTfheyrIJpbVa2hqq+q6mpVXV/0+4bew5qp6tyiOxxTVbXmXs9vp6qzVXWDqi5M9TtZ59xy59yavf7TbhFpnsqxkH1RWTci0kdERjnnPnPOrReRW0Xk9ykeC1nGukGyIrRmUECism6cc18650aJyGepn01uBdHcSuw8/ioiTUSksYhsE5FHvMdcLCJ/FJH6IrJLREaIiKhqAxGZJrE7rDVF5H9EZJKq1vFfRFUbFy2Sxr9UiKq2V9WNIrJJRHqIyPC0zgzZFJV1c6SILNwrLxSRuqpaK8XzQnaxbpCsqKwZEZGWRT9eXqSqN6lqmfRODVkUpXVTUIJobp1za51zk5xzW51zm0TkdhHp4D1srHPuU+fcFhG5SUR6q2ppEblIRF5zzr3mnNvjnHtTROaJSJdiXmeZc666c25ZnFo+KBpLaCgi94rIkoycJDIuQuumiohs3Cv/9PuqaZwesoR1g2RFaM38XUSOEpH9JXbz5XwRGZSRk0TGRWjdFJwgmltVraSqT6rqUlX9UWL/A1cv+gf+yfK9fr9URMqKSG2JfUfUq+i7lg2qukFE2otIvXRqcs59KyLTRWR8OsdB9kRo3WwWkb3fePjT7zelcCxkGesGyYrKmnHOfeOcW1zU7HwiIreISM8UTwtZFpV1U4hC+XHEQBE5VETaOudWqWoLEfmXiOhej2m01+8bS2xAeo3EFsZY59xlWairjIg0y8JxkRlRWTeficixEhvYl6Lff++cW5uBYyPzWDdIVlTWjM95NSBaorpuIq8Q79yWVdUKe/0qI7Efw20TkQ1Fw9RDi3neRap6hKpWkth3qxOdc7tF5DkR6aaqv1XV0kXHPLmYoe2EVPXCotkVVdUmEvsRwtspnykyKbLrRkTGiMglRa9TQ0SGiMgzqZwkMo51g2RFds2o6umqWrfo94dJ7MfYU1M8T2RWlNeNqmoFESlXlCtoxLcdLMTm9jWJ/WP/9GuYxN60VVFi363Mkdg4gG+sxC78q0Skgoj0E4ntcCAiZ4nIDSKyWmLf7QySYv5uihrXzfrLQ9dHiMhsif24cJaIfCkiJfK7pgiK7Lpxzk0XkXtE5F2J/VhpqRR/EUPusW6QrMiuGYltG/exqm4pqnOyiNyR/CkiC6K8bpoU1fTTbgnbJNbfRJY6VxD78QIAAAAJFeKdWwAAAKBYNLcAAAAIBs0tAAAAgkFzCwAAgGAktc+tqvLuswLmnMv5foasmYK3xjn3s49rzDbWTWHjWoMUcK1BKopdN9y5BRDP0nwXAKBE4FqDVBS7bhLeuVXVviLSN+PlIFisGaSCdYNksWaQCtZN+JLa55bb94WNHxUiBfOdc21y/aKsm8LGtQYp4FqDVBS7bhhLAAAAQDBobgEAABAMmlsAAAAEg+YWAAAAwaC5BQAAQDBobgEAABAMmlsAAAAEg+YWAAAAwaC5BQAAQDBobgEAABAMmlsAAAAEg+YWAAAAwSiT7wKyqVGjRiZfffXVJl9zzTUmL1++3OQHH3zQ5IkTJ8Z9PArPlClTTO7WrVtaxytVyn6/ePPNN5u8ceNGk6dNm2byokWL0np9RFOVKlVMHjRokMknn3yyybNmzTJ5/fr1Jj/xxBMmb9u2zeRdu3alUiaSUK5cOZM7duxo8gUXXGByrVq1TK5fv77Jn3zyicmLFy82+f/9v/+XUp0o2YYNG2Zyhw4dTPavPaqa5Ypygzu3AAAACAbNLQAAAIJBcwsAAIBgqHNu3x+suu8PzoN27dqZ/OKLL5rsz+B++OGHJjds2DDu4/0Z28aNG6dUZ74453I+TJPvNVOpUiWTn3zySZP9ubhk/n8ojj+vlOh433zzjck33nijyRMmTEirngyY75xrk+sXzfe6SVenTp1Mfumll0yuXLmyycmuG9+jjz5q8sCBA03esWNHUsdLVwjXmgMPPNDkAQMGmHzRRReZXL16db8ek1evXm2yP4f9/fffm9ykSROTzzvvPJMjcG3INK41GeDP2A4dOjTu49977z2TTznllAxXlHXFrhvu3AIAACAYNLcAAAAIBs0tAAAAglHQ+9z6M7GJZmzPPffcuI/3+X/eq1cvk3v37p3U8ZB7rVq1Mvn888/PUyXFa9q0qcnjxo0z2Z/z/uijj0zO9SwlYvyZ2ZtuusnkK6+8Mu7jff6M7ddff21y3bp1Ta5atarJf/7zn03esmWLyYMHD477+hBp3ry5yTNnzjS5dOnSJvsztP/85z9NnjRpkskvv/yyyRUqVIhbjz+P7++rC2RCAc7Y7hPu3AIAACAYNLcAAAAIBs0tAAAAglHQM7f3339/3D/396H15xcT8WdqZ8+ebXLPnj1NZuY2/8qXL2/ytddem6dKMmPWrFkmDxkyxOQ777wzl+WgiH9tSHed9ejRw2R/X9zTTjvN5PHjx5vs77G6adOmtOopiU4++WST/X8Df2Z2+vTpWX193xtvvJHR10OYEu1re/PNN+eokvzizi0AAACCQXMLAACAYNDcAgAAIBgFPXPrz9C2a9fO5AYNGsR9fLIaNmxo8ooVK9I6HjKvZcuWJnfp0iVPlWTHMccck+8SSqTTTz/d5Pvuuy/u47///nuT//a3v5n85ptvmpxofnPGjBkm//WvfzV5wIABJv/617+Oezz83NNPP53T1/O/Pk2ePDnu49esWZPNcoCgcOcWAAAAwaC5BQAAQDBobgEAABCMgp65HThwYNycrkaNGsXNc+bMyejrIfNUNe6flyplv7/bs2ePyStXrjT5jDPOMHnhwoUmd+jQwWR/TXbt2jVuPYnq8/dXXbBggcl33313UsfHvunXr5/JNWrUiPv4888/3+T33nsvo/WMHTvWZH/m1n//QefOnU3O9B6tSMzfi9jfq7hSpUomn3vuudkuCSWQ/zUqVNy5BQAAQDBobgEAABAMmlsAAAAEo6BnbrOtZ8+ecf/8ww8/zFEl+CX+HPTw4cNNds7Ffb4/Y7ts2TKTe/XqZbI/Y+t7//33Td6+fbvJbdu2NblWrVpJ1eefT58+fUx+/vnnTWYv5tQcdthhJie7b2y+/979meA//OEPJjNzm33+jO2IESNM9tfUokWLTJ44cWJW6kLJdvLJJ+e7hJzgzi0AAACCkfDOrar2FZG+OagFgWDNIBWsGySLNYNUsG7Cl7C5dc6NFJGRIiKqGv9nvICwZpAa1g2SxZpBKlg34WPmNg5/3tLHTFT++ft5tmnTJq3j+XsXz5s3L6PH++Mf/2jy6NGjTU40g+s75JBDTPb/PlijqfH/HqtWrRr38a+//rrJS5cuzXhN6Tj88MNN9mdy169fn8tygrTffvuZ/Morr5jsz9ju2LHD5EsvvTQ7hQElEDO3AAAACAbNLQAAAIJBcwsAAIBgBD1z6++Bevzxx8d9/NVXXx338ddcc43Jy5cvT704RNKYMWOyevxp06aZ/N5775nco0ePtI5frVq1tJ5fUjVt2tTkxx9/PKnnb9682eSdO3emXVMmffHFFyYzY5s+//+1l19+2eQTTjjBZH+P6o0bN5rcqlUrk2vWrGny4sWLTa5SpYrJ//73v03esGFDMVUDlr/vrf81qVBx5xYAAADBoLkFAABAMGhuAQAAEIygZm4HDBhg8gMPPJDV4zds2NDk4cOHm8xMbvadeeaZGT3exx9/nNHj5dqQIUNMHjVqVJ4qKSwnnniiyeXLl4/7+P/85z8mDxo0KOM1Idr893S0b98+qefXqVPHZP/rh09VTfZneLds2WLyzJkzTfZnKb/77juTJ0yYYPL27dvj1oMwhDJj6+POLQAAAIJBcwsAAIBg0NwCAAAgGEHN3CbaxzYRf+Zo4sSJJrdt29Zkf9/bXr16mdy7d2+T58yZk1Z9+LkOHTqY7M+lJVKqVLS+v/Pr9+vbs2dP3OdH7XwKhb/XY6J15P89Z3tfW//1hg4danKienfs2JHxmkq6Tz/91OROnTqZ3KBBA5Nr1aplsv/1yv83Ovroo032Z2T9fXb9451++ulxs79m/D2+b7zxRpPvvPNOAQoFXwkBAAAQDJpbAAAABIPmFgAAAMEIaub2ww8/TOrx/j64iWZiX3zxRZP9GV3/z/3sf9Y4++Cmb8GCBSbXr18/qecnmmHNNr/+Hj16mOzX5+9t6ZsyZUomyipx/L/XRH/PBx10kMl169Y12Z+PTFfTpk1NPuuss0xOVO/999+f0Xrwc++++25Sj3/ooYfi/rm/17K/72yZMvbLt//1pWfPnia3bt3a5Bo1aph8yCGHmHzzzTebvHbtWpNHjhxZXNlAJHDnFgAAAMGguQUAAEAwaG4BAAAQDE00q2UerLrvDy6B2rVrZ7I/A3zuueea7M/kZptzLrlNYDMg22vG31t43LhxST3f3+vx3nvvNXnw4MGpFbaP/M+j9z/nO9Hnyfv8OW5/NjQF851zbdI9SLJyfa3xZ539efpEWrVqZbI/S52uq6++2mT//QK+Tz75xORTTjnF5HXr1mWkrl8S4rUmNJUrVzbZv3b4++guXbrUZH8OPANKxLUm25Lp6UR+Pls9bNiwDFaTE8WuG+7cAgAAIBg0twAAAAgGzS0AAACCEdQ+t/nm75PrzzD5+w7meuYWiZ133nkmv/LKKyb/61//Mnnr1q1xj1epUiWT/Xmm3r17J1lhfBs3bszo8UqKhQsX5rsE47DDDjO5f//+ST1/xYoVJmd7xhaFZ8uWLSZ36tTJ5JdeesnkBg0amOy/xyTRPvHIDX+GdujQoXmqJL+4cwsAAIBg0NwCAAAgGDS3AAAACAYztxnUqFGjuJmZpMzzZyX9vRibNGmS1PEaNmxo8vvvv2/ytGnTTP7qq69M9velPfjgg03u0qVLUvUk67bbbsvq8VE8fw/rZPe5rVixosnTp083uXHjxnGf/+OPP5r81FNPJfX6wP77729yzZo1Td62bZvJ//nPf7JeE5Aq7twCAAAgGDS3AAAACAbNLQAAAILBzG0GvfDCC3H/fOLEiTmqpORYtGiRyd9//73JBx54YNznlyplv7/bs2dP3MefccYZGT1eIomON3v2bJNZY/lxwgknmFy5cmWT/T1FmzVrZvJzzz1ncrIztiNHjjR5ypQpcZ+P7PP3hf3222/zVEnx6tSpY/IVV1wR9/GDBw82efXq1RmvCcgU7twCAAAgGDS3AAAACAbNLQAAAIJR0DO3/mdb+7K9r6w/73j88cebPGHCBJNffPHFrNaDn+8vetxxx8V9vD/D6pxL6/Wzfbxly5aZPGDAgLSOj5jly5eb/PDDD5t81VVXxX1++/btTa5Xr17cx7/11lsm+/sx++tm8+bNJvfp08fkqVOnxn09ZF/nzp1Nvvzyy00+++yzc1mOlCljv7z36NHD5BtuuMHko446yuRHHnnE5CeeeCKD1QHZxZ1bAAAABCPhnVtV7SsifXNQCwLBmkEqWDdIFmsGqWDdhC9hc+ucGykiI0VEVDW9n7GiRGDNIBWsGySLNYNUsG7Cp8nMBEZtEfgzrL169TLZn3kdOHCgyf6cnc+f6fVfr1GjRhl9vWxzzmmuXzPXa6Zq1aomP/DAAyb/4Q9/MFnV/pWkOyOb6eN99913Jvtze/PmzUvr+PtgvnOuTbZfxJfva42/z+ysWbNM9vcw9fmz0ZUqVTK5du3aJvvrxp/JvfTSS01eunRp3NfPt5JwralevbrJ/vV95cqVJvtz3NOnT0/r9f2vd7Vq1TK5e/fuJh900EEm+2vu0UcfNfmaa64xeefOnamUmYwSea3JtGHDhpk8dOjQpJ7vr4sCUOy6YeYWAAAAwaC5BQAAQDBobgEAABCMgt7ntnfv3ibff//9JvszQ/6Mks+fmfJnan3+PKc/Y4vc27Rpk8n9+/c3+Y033jD5ySefNLlatWrZKewX7N6922R/L8nRo0ebvHDhwqzXhJ/PzH766acmJ5q59Wd2ff6s9J133mmyv063bt0a93jIPX82sWzZsiYffPDBJj/00EMZfb1k5/n9a+O4ceNM9vfM3rVrV1LHR2G6+eab811CVnDnFgAAAMGguQUAAEAwaG4BAAAQjILe5zYRf59af0b2+OOPN9mfuX3wwQdNnjhxYtzHR11J2HsyWa1atTL5pJNOivt4f2/LIUOGmJxoLs6fu/v8889NHjVqVNzXzwP2nhSRChUqmHz66aebPGnSpLjPHzFihMk33nijyVu2bEmjuugpideanj17mnzMMceY3Lp1a5M7d+6c1PFnz55t8uLFi+M+3p/bnjFjhsmrV69O6vVzgGtNBpx88skmv/vuuya/9957Jp9yyilZrijr2OcWAAAAYaO5BQAAQDBobgEAABCMoGduYZXEOTikjTk4JI1rDVLAtQapYOYWAAAAYaO5BQAAQDBobgEAABAMmlsAAAAEg+YWAAAAwaC5BQAAQDBobgEAABAMmlsAAAAEg+YWAAAAwaC5BQAAQDBobgEAABAMmlsAAAAEg+YWAAAAwaC5BQAAQDBobgEAABCMMkk+fo2ILBWR2kW/j6oo15ev2prk4TVFWDOZwrqJJur7OdZMfNRXPNZNfNRXvGLXjTrnkj6Sqs5zzrVJu6QsiXJ9Ua4tm6J+3tQXTVE/b+qLnqifM/VFU9TPm/qSw1gCAAAAgkFzCwAAgGCk2tyOzGgVmRfl+qJcWzZF/bypL5qift7UFz1RP2fqi6aonzf1JSGlmVsAAAAgihhLAAAAQDBobgEAABAMmlsAAAAEg+YWAAAAwaC5BQAAQDBobgEAABAMmlsAAAAEg+YWAAAAwaC5BQAAQDBKRHOrqu+p6qW5fi4KG+sGqWDdIFmsGaSCdfPLCqq5VdUlqtop33X8ElUtr6oPqupKVV2vqo+patl811XSRX3diIioalNVfVVVN6nqGlW9J981lXRRXzcac5uqfquqG4u+WB2Z77pKsgJYM+ep6pdF6+UHVX1WVffLd10lXQGsm9+r6m5V3bzXr5PzXVc8BdXcFoDBItJGRI4SkUNEpJWIDMlrRYg8VS0nIm+KyDsicoCINBSR5/JaFApBLxH5o4icKCI1ReRDERmb14oQdbNE5ATnXDURaSoiZUTktvyWhALxoXOuyl6/3st3QfEE0dyqao2iu16ri+6YvqqqDb2HNVPVuUXfsU5V1Zp7Pb+dqs5W1Q2qujCN70i6icgI59w659xqERkhsS8+iKAIrZvfi8hK59wDzrktzrn/Ouc+TvFYyLIIrZuDROQD59w3zrndEvuG6IgUj4Usisqacc4td86t2es/7RaR5qkcC9kXlXVTiIJobiV2Hn8VkSYi0lhEtonII95jLpZYo1lfRHZJrPEUVW0gItMk9t1rTRH5HxGZpKp1/BdR1cZFi6TxL9ShRb/2zg1VtVqK54Xsisq6aSciS1T1dY2NJLynqkenfXbIlqism/Ei0lxVD9HY+FMfEZme5rkhO6KyZkRV26vqRhHZJCI9RGR4WmeGbIrMuhGRlkVfnxap6k2qWia9U8sy51zB/BKRJSLSaR8e10JE1u+V3xORu/bKR4jIDhEpLSLXichY7/lviEifvZ576T7Wd5vEfuxTR2I/Xv6HiDgRqZfvv7uS/KsA1s0MEdkpIqeLSDkRGSQi34hIuXz/3ZXkXwWwbsqJyENF15hdIrJYRA7K999bSf4V9TXjHaOBiAwTkUPy/fdW0n9Ffd1IbITlIIk120eLyOcicn2+/97i/Qrizq2qVlLVJ1V1qar+KCJ/F5Hqqlp6r4ct3+v3S0WkrIjUlth3RL2KvmvZoKobRKS9iNRLoZTbReRfIrJARGaLyBSJNS0/pHAsZFmE1s02if14+XXn3A4RuU9EaonI4SkcC1kWoXUzVER+JSKNRKSCiNwsIu+oaqUUjoUsitCa+V/OuW8ldqd/fDrHQfZEZd242OjTYufcHufcJyJyi4j0TPG0ciKI5lZEBorIoSLS1jm3n4icVPTf9x4RaLTX7xtLrOlcI7GFMdY5V32vX5Wdc3clW4Rzbptz7i/OuQbOuaYislZE5rvYPByiJxLrRkQ+ltjdNxSGqKybY0XkBefcCufcLufcMyJSQ5i7jaKorBlfGRFploHjIDuium6cV0PkFGJzW1ZVK+z1q4yIVJXY3a8NRcPUQ4t53kWqekTRXY1bRGSi+783YXRT1d+qaumiY55czNB2QqraQFXra0w7EbnpF2pB7kV23RQdq52qdir6jvxqiV2cvkjhWMisKK+bf0rszkxdVS2lqr+T2F2br1M6U2RKZNeMql5YNF+pqtpEYj9tfDvlM0UmRXndnK6qdYt+f5jEepupKZ5nThRic/uaxP6xf/o1TGID8RUl1hDMkeLfVDFWRJ4RkVUS+xFeP5HYu0dF5CwRuUFEVkvsu51BUszfTdFFYbP+8tB1M4mNI2wRkWdFZLBzbkbyp4gsiOy6cc59KSIXicgTIrK+6LhnFo0oIL8iu25E5G4RWSixMagNIjJARHo45zYkd4rIsCivmSMk9jVqs8TeH/KliFyW9BkiG6K8bjqKyMequqWozskickfyp5g7WjQsDAAAABS8QrxzCwAAABSL5hYAAADBoLkFAABAMGhuAQAAEIykPj5NVXn3WQFzzuV8XzrWTMFb45z72cc1ZhvrprBxrUEKuNYgFcWuG+7cAohnab4LAFAicK1BKopdNwnv3KpqXxHpm/FyECzWDFLBukGyWDNIBesmfEntc8vt+8LGjwqRgvnOuTa5flHWTWHjWoMUcK1BKopdN4wlAAAAIBg0twAAAAgGzS0AAACCQXMLAACAYNDcAgAAIBg0twAAAAgGzS0AAACCkdTH7wLIrTPOOMPkgw8+2OQOHTqY/MILL5g8bty47BQGAEBEcecWAAAAwaC5BQAAQDBobgEAABAMZm6BPGrUqJHJzz//vMktW7Y0uWLFiiZ//PHHJo8cOdLkL7/80uSPPvoopTqBkq58+fImDxo0yOT69eub7P+/7c/PO+dMVtW4f+5bv369yXfccYfJw4cPN3n37t1xj4fCNHjwYJMPPfRQk5s1a2byiSeeaHKidbZixQqTjzjiCJM3b968T3XmGnduAQAAEAyaWwAAAASD5hYAAADB0ETzFubBqvv+YESOc04TPyqzWDNWu3btTPbn4tq0aWPy3LlzTR4wYIDJy5YtM3ny5Mkmf/PNNyZfeOGF+1xrkfnOuTaJH5ZZrJvCFuK15qmnnjL5j3/8Y1rHmzlzpslLliwx+fjjjze5efPmSR3/3XffNblPnz4mf/vtt0kdLwe41ohInTp1TL744otN7tGjh8nHHXecyf7sti/RbLc/Y9uwYUOT/Rlef93mQbHrhju3AAAACAbNLQAAAIJBcwsAAIBgBL3PbYsWLeJmf2bK3//N3zfwq6++MnnVqlUmT58+PYUqEZIyZez/UpdffrnJI0aMMHnLli0mf/DBByZfdNFFJvvzUL5evXqZfPDBB8d9PIDiPfzwwyb/7ne/M/nBBx80ecqUKSYn2lN6x44dJu/atcvkcuXKmexfW2rUqGGyv0d2hw4dTH7rrbdMPu2000xevnx53HqRG++//77J/r6127dvN/npp582edOmTSYvWLDA5P/85z9xX3/RokUmz5kzx2R/v+eo4s4tAAAAgkFzCwAAgGDQ3AIAACAYBbXPbe3atU3u3Lmzyf4MbZMmTUxu3Lhx3OOXKmV7/T179sR9/MaNG03++OOPTe7du7fJa9asiXu8bAtx78mo+fOf/2zyQw89ZLK/x6A/Uztu3LjsFJY69p5E0kK41owdO9bkU0891eSWLVua/MMPP2Ty5dM2f/58k/33nHz++ecm+19P87APbom81rRu3dpk/30XX3/9tcn+rPR3332XncKK+Huz+7Pk/ux4HrDPLQAAAMJGcwsAAIBg0NwCAAAgGAU1czt69GiT/c/KTjQjm0iyM7eJfPLJJyafc845Juf6M5lDmIPLt0MOOcTkP/3pTyZfddVVcZ9funTpjNeUZSVyDq7Q+eu0a9eucR/v/7m/P7K/l+att94a93ghXGuOOeYYk+vUqWPyzJkzTY7A7KFxwAEHmOzvn9q8eXOT/X1w/TXh78ObBSXiWuP3Gffff7/J/fr1M/nCCy80efz48dkprHAxcwsAAICw0dwCAAAgGDS3AAAACEakZ279/dVuuukmk/19+fwZWX+m9dxzzzV57dq1SdVz1llnmXzxxRebfOyxx5rsz9bMmzfP5LZt2yb1+ukKYQ4u3/xZw+uvv97krVu3mnz55ZebHMF9bBMpEXNw+VarVi2T/XnPM844w+SqVauafMkllyT1eoneX+Cv43Xr1pns7yHu41oTPeedd57J/ntYypcvb3KnTp1Mfvfdd7NT2P8pEdeaSpUqmbxp06a4j2/VqpXJCxcuzHhNBY6ZWwAAAISN5hYAAADBoLkFAABAMMrku4C9de/e3eRnnnnG5MqVK8d9/l133WXyxIkTTU53VmXEiBEmf/zxxya/+eabcZ9/6KGHmuzP8E6dOjWN6pANgwcPNnngwIFxHz906FCTC3DGFvvAn0/s0qWLyf58o0/VjqT68/cNGjRI6vnJvHdC5Ocztu+9957JN954o8lz5sxJ6viIHn9/VH//VH8N/+1vfzO5Xr162SmshGncuHG+SygRuHMLAACAYNDcAgAAIBgJxxJUta+I9M1BLQgEawapYN0gWawZpIJ1E76Eza1zbqSIjBTJ/n5wLVq0MNnfy/GDDz4weezYsSb7n3+ebf6cWtmyZU325+D88/H3xQ1l5jaXayZdZcrY/wX8fWlvv/12k7ds2WLy3LlzTZ4wYUIGqytZ8rlu/D21GzVqFPfx1113ncn+tSuRdGdm/fcPLFq0KO7j/Wvj5s2bTf7qq69MTnYP8HwppGtN1PjXLn/m1t97uX379ib7X48LSS7XTcWKFU32Z5l9I0eONPmTTz7JeE0lAWMJAAAACAbNLQAAAIJBcwsAAIBg5HWfW3/ecb/99jPZ34tx1KhRJo8ZMyY7he2jhg0bmuyfzwMPPGCyv6/thg0bslIX9p0/Y/vQQw/FffyKFStMnjdvnsn+nJr/eETDlClTTO7YsaPJ/pycL92Z2UT8/ZH92e9vv/3W5ESfT4/o89+z4a+xRHbt2mWy//XT98ILL5g8bNgwk0uXLm3yQQcdZHIhz9zmkr+/vf9eG9+OHTtMvv766+M+vnbt2ib7e2Qn2t//xx9/NNm/Nvr8a0+idZYv3LkFAABAMGhuAQAAEAyaWwAAAAQjrzO3VapUMfmYY47JUyXFq169usn9+/c3+aqrrjK5WrVqJvv78DZv3jxzxSEjOnToYLI/51aqlP3+z5+f8vOAAQNMHjhwoMnDhw9PpUxkWNeuXU1euXJlUs/35+sPOOCApJ7vzzMiPP7Xg3PPPdfk4447zuRzzjkn7vMTee2110z+/vvvTZ42bZrJs2bNMtl/D4j/9Q/7pl69eib7fUAif/nLXzJZjvTo0cPkRO8XSPQ1aubMmSb7s9uPP/54khVmB3duAQAAEAyaWwAAAASD5hYAAADByOvMrT/j489y+POQ/nxjug477DCT/bm5G264weRTTjklo6+P3GvdurXJp59+usn+/JG/h98rr7xicqVKlUw+9dRTTb7ppptMZuY2Grp3726yP4+YSKNGjUxevHhxUs9/8cUXTfb3xJ4zZ05Sx0P+nXTSSSY/9dRTJmf7PRddunSJ++d/+MMfTP7444/jPv6///2vyf5ML4pXt25dk5s1a2ZysvsX+/x9a9euXWty+fLlTT7hhBMy+vr+OvezPzt+ySWXmLxs2bK0Xn9fcecWAAAAwaC5BQAAQDBobgEAABCMvM7cJuvaa681uX79+iY//fTTJvuzHj5/FsWfiYrqZyYjdf6+sxUrVoz7eH+NfPTRRyb7802TJ082mTntaEp2xta3detWk1esWGFyw4YN4z7f33vS/3z4Xr16mezP1SH/9ttvP5MnTZpksn9t+Nvf/mby3Llz4x7/3XffNdnfG/m7774z2d9H199H/vrrrzc50b7y/hpnDe6bBQsWmNyyZUuTe/fubXKDBg1Mvueee0zesWOHyf6/w7Zt20xOdw/uRC6//HKTL7vsMpP99534XzP9x7/00ksZrO7/cOcWAAAAwaC5BQAAQDBobgEAABAM9ff1jPtg1X1/cAb4e0c2btzY5FKlbG+e7oxspo8Xtc+Pd86lt8FdCnK9Znzt2rUz+eWXXza5Zs2aJvt7L/uzkIn4n7Ptz1b6c+DPPvtsUsfPg/nOuTa5ftF8r5tk1apVy2R/T9EhQ4aYXLVqVZP96/Azzzxj8qWXXppmhblVEq41Y8aMMfnCCy80efr06SZ37do16zXF061bN5PHjx9vcoUKFUz2Z279NZsFXGsKUL169UweNmyYyf7XPH+f3uOOO87k3bt3J1tCseuGO7cAAAAIBs0tAAAAgkFzCwAAgGBEep9bf3bjoYceMtmfAUp3Rnbz5s0mr1+/3mR/PzrfmjVr0np9ZF6jRo1M9mdsfbfddls2y5Gjjz46q8dHfvh7T953330m+3uc+vvi+vw9ShE9/qxh1P3www8mJ5ptnDBhQjbLQSD8/Zb9fXAvuOACk1u0aGHySSedZLK/v3OquHMLAACAYNDcAgAAIBg0twAAAAhGpGdu/T1A/T1Ijz32WJMvvvhik5s0aWKyP7P7448/muzvv+bnr776Km691113Xdw/R+6patzs8+d/hg8fntHXnzlzZlrHQzQdcsghJh9//PEmP/LIIyb7+9oms984sC8qVapk8qOPPmpy5cqVTfbfM3LEEUdkpzAEzZ+pLVeuXF7q4M4tAAAAgkFzCwAAgGDQ3AIAACAYkZ659U2dOjVufvLJJ032Pyv722+/NXnXrl0mH3DAASb7nx3umzNnjsmTJ0+O+3jk3iuvvGLyRx99ZHLLli1NPvPMM00eO3asyf7cmj+HXb9+fZP9WUp/zSIa2rVrZ7K/P7JvwIABJjdv3tzkRPsp+z788EOTH3vssaSej+jxZw1Lly5tcqJ9ZpNVvXp1k+fNm2fyQQcdZPK6detM7tq1q8lffPFF5orD//L7Ev///RkzZph84403muz3LflWt25dk0eMGGFymTK2zfQ/j2Dnzp1ZqYs7twAAAAgGzS0AAACCQXMLAACAYBTUzG0i33//fVrPf/HFF03296r0bd++3eTNmzen9frIvG3btpl8//33m/zcc8/Ffb7/udinnXaayatWrTL5yCOPTLZERIC/T+3tt99ucr169Uz29y9Odp/aadOmmXzuueea7K9bRI9/7TjxxBNNPvXUU02+6aabTB42bFhar+/Pib/88ssm16pVK+7z/VlOf0YX2VGqlL2neMwxx8TN5cuXN/nqq6/OSl2/xH8fSbdu3Uy+6667TN5vv/3iHu+2224z+YMPPkijul/GnVsAAAAEg+YWAAAAwUg4lqCqfUWkbw5qQSBYM0gF6wbJYs0gFayb8Gkys2KqGtQHoLdv397kmTNnmuzvx+Zr2rSpyUuXLs1MYVninNPEj8qsqK0Zfw6te/fuJg8ZMsTkxo0bm5zo/5e1a9eaPH78eJP79++/L2VGyXznXJtcv2i+180ZZ5xhsr+/8b/+9S+TV65cabK//7G/v/L777+fbomRVhKvNW+++abJ/syt//XkqaeeMnnKlCkmly1b1mT/WtWjRw+Tq1WrZrJ/rbrkkktMfv75502OwP6pJeJa48/rN2vWzGT/WlGpUiWTv/zyS5PvueeeuH+eiL9u/HX1u9/9zmR//+ZE/K+pd999t8mJ+qx9UOy6YSwBAAAAwaC5BQAAQDBobgEAABCMEj1zO3r0aJP79Olj8o4dO0z25+78WZL//ve/Gawu80riHFy6/M9/9/9/WbJkicmdO3c2+euvv85KXTlUIubgkFkl8VrTokULk/29kv1rQ7ZdfPHFJvszthHEtUZErrzySpMfeOABk5OdefWlu0f3t99+a/LUqVNNnjx5ssn++wsyMGPrY+YWAAAAYaO5BQAAQDBobgEAABCMEjVze+CBB5o8adIkk/2ZqcWLF5vcvHnzbJSVMyVxDg5pYw4OSeNaI7LffvuZfPbZZ5vs71t75plnJnV8f79Qf0/tzz77zGT//QMRxLWmGP5+/P5+xW3btjX50EMPjXu8RDO3/j65fp90yy23mLxz5864r5cDzNwCAAAgbDS3AAAACAbNLQAAAIJRomZux4wZY/L5559vcqlSttdn5jZ9hb5mwBwckse1BingWoNUMHMLAACAsNHcAgAAIBg0twAAAAhGmXwXkEvXXnutyU2aNDHZ309u1KhRWa8JAAAAmcOdWwAAAASD5hYAAADBoLkFAABAMErUzO2qVatM7tChQ54qAQAAQDZw5xYAAADBoLkFAABAMGhuAQAAEAyaWwAAAASD5hYAAADBoLkFAABAMGhuAQAAEIxk97ldIyJLRaR20e+jKsr15au2Jnl4TRHWTKawbqKJ+n6ONRMf9RWPdRMf9RWv2HWjzrmkj6Sq85xzbdIuKUuiXF+Ua8umqJ839UVT1M+b+qIn6udMfdEU9fOmvuQwlgAAAIBg0NwCAAAgGKk2tyMzWkXmRbm+KNeWTVE/b+qLpqifN/VFT9TPmfqiKernTX1JSGnmFgAAAIgixhIAAAAQDJpbAAAABIPmFgAAAMGguQUAAEAwaG4BAAAQDJpbAAAABIPmFgAAAMGguQUAAEAwaG4BAAAQDJpbAAAABKNENLeq+p6qXprr56KwsW6QCtYNksWaQSpYN7+soJpbVV2iqp3yXccvUdWjVPUNVV2jqi7f9SCmANbNE6q6ea9f21V1U77rKukKYN2UV9UHVXWlqq5X1cdUtWy+6yrJCmDNnKeqX6rqRlX9QVWfVdX98l1XSRf1dSMioqoDVHVV0doZrarl811TPAXV3BaAnSLyoohcku9CUDicc1c456r89EtExonIhHzXhcgbLCJtROQoETlERFqJyJC8VoSomyUiJzjnqolIUxEpIyK35bckRJ2q/lZi15uOInKgxNbOzfmsKZEgmltVraGqr6rq6qI7GK+qakPvYc1UdW7Rdx1TVbXmXs9vp6qzVXWDqi5U1ZNTqcM596VzbpSIfJb62SBXorJuvJoqi0gPEXk23WMhOyK0brqJyAjn3Drn3GoRGSEif0zxWMiiqKwZ59xy59yavf7TbhFpnsqxkH1RWTci0kdERjnnPnPOrReRW0Xk9ykeKyeCaG4ldh5/FZEmItJYRLaJyCPeYy6W2IW/vojsktgXAlHVBiIyTWLfvdYUkf8RkUmqWsd/EVVtXLRIGmfpPJBbUVw3PURktYj8PZUTQk5EZd1o0a+9c0NVrZbieSF7orJmRFXbq+pGEdkksevN8LTODNkUlXVzpIgs3CsvFJG6qlorxfPKuiCaW+fcWufcJOfcVufcJhG5XUQ6eA8b65z71Dm3RURuEpHeqlpaRC4Skdecc6855/Y4594UkXki0qWY11nmnKvunFuW5VNCDkR03fQRkTHOOWa2IypC6+Z1EemvqnVU9QAR6Vf03ytl4DSRQRFaM+Kc+6BoLKGhiNwrIksycpLIuAitmyoisnGv/NPvq6ZxelkVRHOrqpVU9UlVXaqqP0rsrlf1on/gnyzf6/dLRaSsiNSW2HdEvYq+a9mgqhtEpL2I1MtR+ciTqK0bVW0ksQvXmFSPgeyL0Lq5XUT+JSILRGS2iEyR2Nz/DykcC1kUoTXzv5xz34rIdBEZn85xkD0RWjebRWTvNx7+9PvIvvE5iOZWRAaKyKEi0tY5t5+InFT03/f+kV2jvX7fWGJfBNZIbGGMLfqu5adflZ1zd+WicORV1NbNxSIy2zn3TRrHQPZFYt0457Y55/7inGvgnGsqImtFZL5zbncqJ4WsisSaKUYZEWmWgeMgO6Kybj4TkWP3yseKyPfOubUpHCsnCrG5LauqFfb6VUZit8a3iciGomHqocU87yJVPUJVK4nILSIyseiLwHMi0k1Vf6uqpYuOeXIxQ9sJaUwFESlXlCtoxLfLKEEiu272crGIPJPG85F5kV03qtpAVesXXXfaSexHksXVgtyK8pq5sGi+UlW1icTu/r+d8pkikyK7biT208RLil6nhsR2ZXkmlZPMlUJsbl+T2D/2T7+GSWwgvqLEvluZI7EftfjGSuwfY5WIVJCi+TTn3HIROUtEbpDYG3mWi8ggKebvpuiisFl/eei6SVFNP+2WsE1Evkzu9JAlUV43oqrHS2wGji3AoiXK66aZxMYRtkhsd43BzrkZyZ8iMizKa+YIia2ZzRLbFuxLEbks6TNENkR23TjnpovIPSLyrsRGH5ZKxL+RVt63AgAAgFAU4p1bAAAAoFg0twAAAAgGzS0AAACCQXMLAACAYJRJ5sGqyrvPCphzThM/KrNYMwVvjXPuZx/XmG2sm8LGtQYp4FqDVBS7brhzCyCepfkuAECJwLUGqSh23SS8c6uqfUWkb8bLQbBYM0gF6wbJYs0gFayb8CW1zy237wsbPypECuY759rk+kVZN4WNaw1SwLUGqSh23TCWAAAAgGDQ3AIAACAYNLcAAAAIBs0tAAAAgkFzCwAAgGDQ3AIAACAYNLcAAAAIBs0tAAAAgkFzCwAAgGDQ3AIAACAYNLcAAAAIRpl8FwAAQGguvPBCk4cNG2Zy8+bNTXbOmTxp0iSTp06davKUKVNM3rx5cwpVotD17t3b5KuuusrkGTNmmHzrrbdmvaYo4M4tAAAAgkFzCwAAgGDQ3AIAACAY6s/5xH2w6r4/GJHjnNNcvyZrpuDNd861yfWLsm4KG9cakcWLF5vcuHHjjB7/888/N/mOO+4wedy4cRl9vRzgWrMPDjvsMJPfeecdk+vVq2fyihUrTG7durXJP/zwQwary4ti1w13bgEAABAMmlsAAAAEg+YWAAAAwQh6n9s2bewYxuWXX27yIYccYvLXX39t8uTJk02eO3euyatXr063RORZ9erVTfb3nvT3qvT179/f5GRm2EVEVq1aZfKvf/1rk5cuXZrU8QBEQ8+ePU3+4osvknp+jx49TO7evbvJnTt3Nnns2LEmt2jRwuQbb7zR5F27diVVD6JhxIgRJvszth999JHJLVu2NLlhw4YmBzBzWyzu3AIAACAYNLcAAAAIBs0tAAAAghHUPrf+7MmcOXNMbtSokcm7d+82uXTp0nGPP3/+fJMHDBhg8gcffLBPdeYLe0/+fIb2hhtuMPnQQw9N6niq9q904cKFJpctW9bkww8/PO7xTjjhBJP/8Y9/JFVPFrD3ZApOP/10kx999FGTly1bZvJzzz1n8tNPPx33+GeffbbJTZo0MXn48OH7UmbWcK3JPn+/Un+m9qyzzjLZ//o0evRok5999tkMVpcSrjXF8P9ff/75501+/fXXTfa/xvn/7m+//bbJ1113Xbol5hv73AIAACBsNLcAAAAIBs0tAAAAghHUPrd79uwxuUqVKiZv3LjR5PPPP99kf8/TO++802R/xinRTBPyz/83fuKJJ0yuWLGiyevXrzfZ3+t4wYIFJs+cOdNkf1/aMmXs/2L+rKX/+hdccIHJEZi5RTH8z3efMWOGyf78v78ODjzwQJNPPPFEk6+44gqTb7vtNpNvuukmk+vUqWNyvmdukX3+e0B69eplsn/tOuOMM0zevn27yRGYuUUxHnvsMZP9rxnjx483+bzzzjO5Vq1aJvvvRQoVd24BAAAQDJpbAAAABIPmFgAAAMEIaub2+++/N9mfge3WrZvJ/mdr+7Mr/vOvvPJKk//0pz+ZPHv2bJNfeumlBBUj0ypVqmTypZdearI/p+bPMs6aNcvkbdu2pVWPPx+VyIsvvpjW6yE7HnroIZP79u1rcvny5U32Z6/LlStnsj+T6++X7P/50KFDTT722GNN/vbbb4srGyWIv8Z27NiRp0qQDn+vdf+9Q59++qnJL7/8sslvvfWWyf58/9VXX23yhx9+aPKqVav2tdRI484tAAAAgkFzCwAAgGDQ3AIAACAYQc3c+vzPYPZnbkeNGmXysGHDTD7zzDNNbtWqlcmVK1c22Z/3RO5t3brV5I4dO+apkpiBAwea7M/gfv311yb/+9//znpNSOyiiy4y+c9//rPJpUrZ+wL+rPTo0aNNfvzxx03259ouv/xyk++55x6T/RnbTZs2mfz73/9eUNj8rx/+DG379u1N9vdZ79y5s8n169c32Tln8ubNm1OqE9nVr18/k/2Z2wceeMBkf79ify93fx2cdNJJJn/xxRcmDxgwwORnnnkmfsERxZ1bAAAABIPmFgAAAMFIOJagqn1FpG+ixwE/Yc0gFawbJIs1g1SwbsKn/hxO3Aer7vuDI8D/LO2pU6ea7O8tmYg/2+LPyY0ZMyap4+Wacy65E86AQlsz6WrTpo3J7777rsn+zK0/k+vvpxoB851zbRI/LLNyvW769Olj8vDhw01es2aNyf7nvT/yyCMmv/HGGyb7e1f685LXXXedyT169Ihb75IlS0xu2rRp3MfnGteaxO69916Tzz77bJMPOuigtI7v74f66quvmnzjjTemdfwsKBHXGp8/U7tgwQKTmzVrZvJvf/tbk2fMmBH3+P7XnJtvvtnkQYMGxX2+f2275pprTN65c2fc5+dAseuGsQQAAAAEg+YWAAAAwaC5BQAAQDCC3ufWnzHq2bOnyS1btjTZn0HyZ3L/+c9/mhz1GVtkn7/fqT8P5c87bdy40WR/Jhf54e8xWq1aNZNfeeUVkx988MG4x/vrX/9qsr+n6IQJE0yuW7fuPtX5k/vvvz+pxyN6unTpYnKiGdtHH33U5Jdeesnk7777zuQVK1aYzL620eR/jfBnbP1/t5UrVyZ1/G3btpk8ePBgk19++WWT/c8H+Mtf/mKyvxe7vy6jgju3AAAACAbNLQAAAIJBcwsAAIBgBD1z6/NnlPzsz6KUKWP/epixhe+SSy4x2d9D0Hf99deb/PHHH2e8JmSevy/tlVdeafL+++9v8g8//GDy7bffbnLDhg3TqmfDhg1pPR/5N2zYMJP9/URr165t8qhRo0xeuHBhVupCtKxbt85kf//iZO3Zs8fkDz74wGT/Wjd69GiTH374YZPr169vclT2T+bOLQAAAIJBcwsAAIBg0NwCAAAgGCVq5jZdEfgMZUTMGWecEffPly1bZvKzzz6bzXKQohdffNHk8847z+QTTzzRZH9vx02bNplctmxZkytUqGCyP0f3wgsvmHzEEUeY3KFDB5P9vSf9vSkRff5ex02aNDH57rvvNtnft/1Xv/qVyatWrcpgdciVs88+O+6f++8NyrYFCxaY3K9fP5OnTZtmsn+tigru3AIAACAYNLcAAAAIBs0tAAAAglGiZ25r1aplsqrGffzatWuzWQ4KQIsWLUz2Z26dcybfe++9Jm/fvj0rdSE9/v/bPXr0MHnixIkmn3TSSSZXrVo17vH/8Y9/mHzLLbeYPHv2bJOnT58e93h169aN++coPPfff7/Jp512mskdO3Y0+Z133jG5U6dOJq9cuTKD1SFb/D7E99lnn+WokuL5++D669Rfd/77DfL1XiXu3AIAACAYNLcAAAAIBs0tAAAAglGiZ267detmcunSpU3esWOHyf4+gwhf5cqVTb755ptNLlXKfn/41ltvmfz4449npzBk1Zo1a0zu1auXyQcffHBSx/M/D/7HH380uU2bNia3bds2qeOj8Pnz+hdffLHJDz/8sMnnnHOOya+99prJXbp0MZkZ3Gjy+wzfjBkzclTJvjnssMNM9vcAr1atmsn+tTRXuHMLAACAYNDcAgAAIBg0twAAAAhGiZ65PeCAA+L++ahRo3JUCaLq97//vcldu3Y1eevWrSaPHj062yUhD1avXh035xrrLHyrVq0yediwYSb7ey0fffTRJp9wwgkmT5gwIXPFIWPGjBlj8n333WeyP3t96623Zr2meP7973/n9fX3FXduAQAAEAyaWwAAAASD5hYAAADBKFEzt/5nOPft2zfu4/3Pk0f4mjdvbvIdd9wR9/H+fNS4ceMyXhPg8/eWRPg+++wzk1u2bGnyl19+afI111xj8iuvvGLyf//73wxWh2ypVKlSvkswolbPL+HOLQAAAIJBcwsAAIBg0NwCAAAgGCVq5rZOnTomH3jggXEfv3HjxixWgyhQVZNvuOEGkytXrhz3+f4cG5ALBx98cL5LQJ6tXLnS5F27dpl83HHHmVyjRg2Tv/vuu+wUhoy64IILTL7++utz+vqtWrUyuX///ib762jHjh1Zr2lfcOcWAAAAwaC5BQAAQDBobgEAABCMEjVz6/PnLZ1zeaoE+dKjRw+T/c/x9j3zzDMmz5s3L9MloQT65ptvTJ4/f77JrVu3zmU5iKAqVaqYfNFFF5ns7z/qX5s2bNiQlbqQni1btpj8+eefm+zPSvv/zlu3bs1OYUX89yqVLVvW5HvuucfkH3/8Mav17Cvu3AIAACAYCe/cqmpfEYn/UV7AXlgzSAXrBslizSAVrJvwJWxunXMjRWSkiIiq8nN7JMSaQSpYN0gWawapYN2Er0TP3DJji2T3C73tttvSer1zzz3X5BdeeCGt4yEM69atM9nfw5SZ28LjzyaWK1cuqef77wfo1auXyV26dDHZ/3p27733mrxt27akXh+54c/MfvXVVyafddZZJvfp08fkxx9/PDuFFenatavJP/zwg8nDhw/P6uuniplbAAAABIPmFgAAAMGguQUAAEAwSvTMLfvc4le/+lXcP/dnbJcvX25y+fLlTT7nnHNMHjJkiMn9+vVLtkSUQFHZKxL/p1u3bib37Nkz7uOPPPJIk1u2bJnRej777DOT77jjDpMnTpyY0ddDbnz44Ycm+zO33bt3N3nkyJEm7969O63Xb9Cggcmnn366ydOmTUvr+LnCnVsAAAAEg+YWAAAAwaC5BQAAQDBK9MwtM7Y4/vjj4/55zZo1TT788MNN/tvf/mZykyZNTL799ttNfv/995MtESXQfffdZ/KFF16Yp0rwE39e/tRTT83q6/373/82efLkySbffffdJm/evDmr9SA3/Bnaa6+91uTTTjvNZP/aMGbMmLRef9iwYSavXbvW5L/85S9pHT9XuHMLAACAYNDcAgAAIBg0twAAAAiGJjN3qqoFPaTqz0++8cYbJvuf3759+3aTP/jgA5N/85vfZLC67HPOaeJHZVbU18yjjz5q8uWXX57U8/29kp966imTr7jiitQKi475zrk2uX7RqK+bbGvTxv6Vz5071+QlS5aY3LRp02yXlBSuNUgB1xqkoth1w51bAAAABIPmFgAAAMGguQUAAEAwStQ+t+vWrTO5S5cuJq9cudLkcuXKmfzII49kpzDkjb+nX/v27U32Px9+wYIFJvv72Ppz3EAqbrrppnyXAAAFizu3AAAACAbNLQAAAIJBcwsAAIBglKiZW9/q1atNLlu2bJ4qQb74a+DYY4/NUyXA/3n77bdN7tatW54qAYDCw51bAAAABIPmFgAAAMGguQUAAEAw1Ll9/1hlPoO5sPF570gBn/eOpHGtQQq41iAVxa4b7twCAAAgGDS3AAAACAbNLQAAAIKR7D63a0RkqYjULvp9VEW5vnzV1iQPrynCmskU1k00Ud/PsWbio77isW7io77iFbtuknpD2f8+SXVePga/91WU64tybdkU9fOmvmiK+nlTX/RE/ZypL5qift7UlxzGEgAAABAMmlsAAAAEI9XmdmRGq8i8KNcX5dqyKernTX3RFPXzpr7oifo5U180Rf28qS8JKc3cAgAAAFHEWAIAAACCQXMLAACAYNDcAgAAIBg0twAAAAgGzS0AAACC8f8Bom8zp9bt4HoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "startIndex = 300\n",
    "num_row = 5\n",
    "num_col = 5# plot images\n",
    "fig, axes = plt.subplots(num_row, num_col, figsize=(2*num_col,2*num_row))\n",
    "for i in range(25):\n",
    "    ax = axes[i//num_col, i%num_col]\n",
    "    ax.imshow(xTestImg[i+startIndex,:,:], cmap='gray')\n",
    "    ax.set_title('Label: {}'.format(classLabel[i+startIndex]))\n",
    "    ax.tick_params(labelbottom=False)\n",
    "    ax.tick_params(labelleft=False)    \n",
    "    \n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **Deep Machine Learning Workshop 4**\n",
    "\n",
    "# Task 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from numpy import asarray\n",
    "import time\n",
    "from numpy import argmax\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numClasses = 10\n",
    "numFeatures = 784\n",
    "\n",
    "lr = 0.15\n",
    "steps = 5000\n",
    "batchSize = 256\n",
    "iStep = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing \n",
    "### Splits and normalizes data before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# MNIST data\n",
    "(xTrain, yTrain),(xTest, yTest) = mnist.load_data()\n",
    "xTrain, xTest = np.array(xTrain, np.float32), np.array(xTest, np.float32)\n",
    "xTrain, xTest = xTrain.reshape([-1,numFeatures]), xTest.reshape([-1,numFeatures])\n",
    "xTrain, xTest = xTrain/255., xTest/255.\n",
    "print(xTrain.shape, xTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building MODEL \n",
    "\n",
    "expects an output data of 10 classes and uses a softmax activation fuction for the last layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                7850      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 88        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,028\n",
      "Trainable params: 8,028\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(numFeatures,), kernel_regularizer='l1'))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(numClasses, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.872\n"
     ]
    }
   ],
   "source": [
    "# define loss and optimizer\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# fit the model\n",
    "model.fit(xTrain, yTrain, epochs=10, batch_size=128, verbose=0)\n",
    "# evaluate the model\n",
    "loss, acc = model.evaluate(xTest, yTest, verbose=0)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Hidden Neuron Set to 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 30)                330       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                310       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,490\n",
      "Trainable params: 8,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(numFeatures,), kernel_regularizer='l1'))\n",
    "model.add(Dense(30, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(numClasses, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy increases , also the processing time increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.895\n",
      "Processing Time:  8.71819519996643\n"
     ]
    }
   ],
   "source": [
    "# define loss and optimizer\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# fit the model\n",
    "#timing the model performance\n",
    "tic = time.time()\n",
    "model.fit(xTrain, yTrain, epochs=10, batch_size=128, verbose=0)\n",
    "toc = time.time()\n",
    "# evaluate the model\n",
    "execution_time = toc-tic\n",
    "loss, acc = model.evaluate(xTest, yTest, verbose=0)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "print('Processing Time: ', execution_time)\n",
    "    \n",
    "        #Run model and get results to append on a list\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Neuron Set To 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 512)               5632      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,612\n",
      "Trainable params: 18,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(numFeatures,), kernel_regularizer='l1'))\n",
    "model.add(Dense(512, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(numClasses, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### processing time increases  , also a futher improvement in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.930\n",
      "Processing Time:  10.995627880096436\n"
     ]
    }
   ],
   "source": [
    "# define loss and optimizer\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# fit the model\n",
    "#timing the model performance\n",
    "tic = time.time()\n",
    "model.fit(xTrain, yTrain, epochs=10, batch_size=128, verbose=0)\n",
    "toc = time.time()\n",
    "# evaluate the model\n",
    "execution_time = toc-tic\n",
    "loss, acc = model.evaluate(xTest, yTest, verbose=0)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "print('Processing Time: ', execution_time)\n",
    "    \n",
    "        #Run model and get results to append on a list\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 30)                23550     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 8)                 248       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 10)                90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,888\n",
      "Trainable params: 23,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', kernel_initializer='he_normal', input_shape=(numFeatures,), kernel_regularizer='l1'))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(numClasses, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Set to 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "K.set_value(model.optimizer.learning_rate, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There is a reduction in accuracy ( the descent must have overshot)\n",
    "#### Reduction in time it takes to train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.113\n",
      "Processing Time:  8.890690803527832\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#timing the model performance\n",
    "tic = time.time()\n",
    "model.fit(xTrain, yTrain, epochs=10, batch_size=128, verbose=0)\n",
    "toc = time.time()\n",
    "# evaluate the model\n",
    "execution_time = toc-tic\n",
    "loss, acc = model.evaluate(xTest, yTest, verbose=0)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "print('Processing Time: ', execution_time)\n",
    "    \n",
    "        #Run model and get results to append on a list\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Set To 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_33 (Dense)            (None, 30)                23550     \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 8)                 248       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 10)                90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,888\n",
      "Trainable params: 23,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', kernel_initializer='he_normal', input_shape=(numFeatures,), kernel_regularizer='l1'))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(numClasses, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy reduces futher and processing time reduces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.098\n",
      "Processing Time:  7.964528799057007\n"
     ]
    }
   ],
   "source": [
    "# define loss and optimizer\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "K.set_value(model.optimizer.learning_rate, 1)\n",
    "# fit the model\n",
    "#timing the model performance\n",
    "tic = time.time()\n",
    "model.fit(xTrain, yTrain, epochs=10, batch_size=128, verbose=0)\n",
    "toc = time.time()\n",
    "# evaluate the model\n",
    "execution_time = toc-tic\n",
    "loss, acc = model.evaluate(xTest, yTest, verbose=0)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "print('Processing Time: ', execution_time)\n",
    "    \n",
    "        #Run model and get results to append on a list\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Set To 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 30)                23550     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 8)                 248       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 10)                90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,888\n",
      "Trainable params: 23,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', kernel_initializer='he_normal', input_shape=(numFeatures,), kernel_regularizer='l1'))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(numClasses, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model behavees very poorly but its very quick to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.101\n",
      "Processing Time:  9.768633365631104\n"
     ]
    }
   ],
   "source": [
    "# define loss and optimizer\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "K.set_value(model.optimizer.learning_rate, 3)\n",
    "# fit the model\n",
    "#timing the model performance\n",
    "tic = time.time()\n",
    "model.fit(xTrain, yTrain, epochs=10, batch_size=128, verbose=0)\n",
    "toc = time.time()\n",
    "# evaluate the model\n",
    "execution_time = toc-tic\n",
    "loss, acc = model.evaluate(xTest, yTest, verbose=0)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "print('Processing Time: ', execution_time)\n",
    "    \n",
    "        #Run model and get results to append on a list\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model With and Without regularizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_45 (Dense)            (None, 30)                23550     \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 8)                 248       \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 10)                90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,888\n",
      "Trainable params: 23,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', kernel_initializer='he_normal', input_shape=(numFeatures,), kernel_regularizer='l1'))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(numClasses, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Has higher processing time and lesser accuracy compared to withouth regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.888\n",
      "Processing Time:  9.95652174949646\n"
     ]
    }
   ],
   "source": [
    "# define loss and optimizer\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "#timing the model performance\n",
    "tic = time.time()\n",
    "model.fit(xTrain, yTrain, epochs=10, batch_size=128, verbose=0)\n",
    "toc = time.time()\n",
    "# evaluate the model\n",
    "execution_time = toc-tic\n",
    "loss, acc = model.evaluate(xTest, yTest, verbose=0)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "print('Processing Time: ', execution_time)\n",
    "    \n",
    "        #Run model and get results to append on a list\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Without regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_42 (Dense)            (None, 30)                23550     \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 8)                 248       \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 10)                90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,888\n",
      "Trainable params: 23,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', kernel_initializer='he_normal', input_shape=(numFeatures,)))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(numClasses, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.960\n",
      "Processing Time:  9.594746589660645\n"
     ]
    }
   ],
   "source": [
    "# define loss and optimizer\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "#timing the model performance\n",
    "tic = time.time()\n",
    "model.fit(xTrain, yTrain, epochs=10, batch_size=128, verbose=0)\n",
    "toc = time.time()\n",
    "# evaluate the model\n",
    "execution_time = toc-tic\n",
    "loss, acc = model.evaluate(xTest, yTest, verbose=0)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "print('Processing Time: ', execution_time)\n",
    "    \n",
    "        #Run model and get results to append on a list\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add DropOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_48 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 8)                 88        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 10)                90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,028\n",
      "Trainable params: 8,028\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(numFeatures,), kernel_regularizer='l1'))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(numClasses, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy reduces a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.870\n",
      "Processing Time:  8.730173587799072\n"
     ]
    }
   ],
   "source": [
    "# define loss and optimizer\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "#timing the model performance\n",
    "tic = time.time()\n",
    "model.fit(xTrain, yTrain, epochs=10, batch_size=128, verbose=0)\n",
    "toc = time.time()\n",
    "# evaluate the model\n",
    "execution_time = toc-tic\n",
    "loss, acc = model.evaluate(xTest, yTest, verbose=0)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "print('Processing Time: ', execution_time)\n",
    "    \n",
    "        #Run model and get results to append on a list\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Possible HyperParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### learning rate = 0.001\n",
    "#### number of hidden layer = 512\n",
    "#### With regularizer \n",
    "#### Adding Dropout to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_54 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 512)               5632      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,612\n",
      "Trainable params: 18,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(numFeatures,), kernel_regularizer='l1'))\n",
    "model.add(Dense(512, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(numClasses, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.923\n",
      "Processing Time:  13.120967149734497\n"
     ]
    }
   ],
   "source": [
    "# define loss and optimizer\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "#timing the model performance\n",
    "tic = time.time()\n",
    "model.fit(xTrain, yTrain, epochs=10, batch_size=128, verbose=0)\n",
    "toc = time.time()\n",
    "# evaluate the model\n",
    "execution_time = toc-tic\n",
    "loss, acc = model.evaluate(xTest, yTest, verbose=0)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "print('Processing Time: ', execution_time)\n",
    "    \n",
    "        #Run model and get results to append on a list\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    }
   ],
   "source": [
    "print(K.eval(model.optimizer.lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Adam',\n",
       " 'learning_rate': 0.001,\n",
       " 'decay': 0.0,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'epsilon': 1e-07,\n",
       " 'amsgrad': False}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPLY MLP TO CLASSIFY CIFAR10 IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = np.reshape(train_images, (50000, 3072)).astype('float32')\n",
    "x_test = np.reshape(test_images, (10000, 3072)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_17 (Dense)            (None, 10)                30730     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 512)               5632      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,492\n",
      "Trainable params: 41,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu',  input_dim=3072))\n",
    "model.add(Dense(512, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(10,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "1563/1563 - 4s - loss: 2.3043 - accuracy: 0.0979 - 4s/epoch - 3ms/step\n",
      "Epoch 2/18\n",
      "1563/1563 - 3s - loss: 2.3028 - accuracy: 0.0999 - 3s/epoch - 2ms/step\n",
      "Epoch 3/18\n",
      "1563/1563 - 3s - loss: 2.3028 - accuracy: 0.0987 - 3s/epoch - 2ms/step\n",
      "Epoch 4/18\n",
      "1563/1563 - 3s - loss: 2.3028 - accuracy: 0.0979 - 3s/epoch - 2ms/step\n",
      "Epoch 5/18\n",
      "1563/1563 - 3s - loss: 2.3028 - accuracy: 0.0976 - 3s/epoch - 2ms/step\n",
      "Epoch 6/18\n",
      "1563/1563 - 3s - loss: 2.3028 - accuracy: 0.0977 - 3s/epoch - 2ms/step\n",
      "Epoch 7/18\n",
      "1563/1563 - 3s - loss: 2.3028 - accuracy: 0.1005 - 3s/epoch - 2ms/step\n",
      "Epoch 8/18\n",
      "1563/1563 - 3s - loss: 2.3028 - accuracy: 0.0965 - 3s/epoch - 2ms/step\n",
      "Epoch 9/18\n",
      "1563/1563 - 3s - loss: 2.3028 - accuracy: 0.0998 - 3s/epoch - 2ms/step\n",
      "Epoch 10/18\n",
      "1563/1563 - 3s - loss: 2.3028 - accuracy: 0.0976 - 3s/epoch - 2ms/step\n",
      "Epoch 11/18\n",
      "1563/1563 - 3s - loss: 2.3028 - accuracy: 0.0978 - 3s/epoch - 2ms/step\n",
      "Epoch 12/18\n",
      "1563/1563 - 3s - loss: 2.3028 - accuracy: 0.0979 - 3s/epoch - 2ms/step\n",
      "Epoch 13/18\n",
      "1563/1563 - 3s - loss: 2.3028 - accuracy: 0.0988 - 3s/epoch - 2ms/step\n",
      "Epoch 14/18\n",
      "1563/1563 - 3s - loss: 2.3028 - accuracy: 0.0996 - 3s/epoch - 2ms/step\n",
      "Epoch 15/18\n",
      "1563/1563 - 3s - loss: 2.3028 - accuracy: 0.0981 - 3s/epoch - 2ms/step\n",
      "Epoch 16/18\n",
      "1563/1563 - 3s - loss: 2.3028 - accuracy: 0.0966 - 3s/epoch - 2ms/step\n",
      "Epoch 17/18\n",
      "1563/1563 - 3s - loss: 2.3028 - accuracy: 0.0983 - 3s/epoch - 2ms/step\n",
      "Epoch 18/18\n",
      "1563/1563 - 3s - loss: 2.3028 - accuracy: 0.0987 - 3s/epoch - 2ms/step\n",
      "Accuracy: 0.100\n",
      "Processing Time:  56.83862900733948\n"
     ]
    }
   ],
   "source": [
    "# define loss and optimizer\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "#timing the model performance\n",
    "tic = time.time()\n",
    "model.fit(x_train, train_labels,  epochs=18, batch_size=32, verbose=2)\n",
    "toc = time.time()\n",
    "# evaluate the model\n",
    "execution_time = toc-tic\n",
    "loss, acc = model.evaluate(x_test, test_labels, verbose=0)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "print('Processing Time: ', execution_time)\n",
    "    \n",
    "        #Run model and get results to append on a list\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DML-WS4-Task1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
