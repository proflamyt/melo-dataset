{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate lstm example\n",
    "from numpy import array\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataset By Spliting The Input List Into Sequece Of Data :\n",
    "    * Create two sets of lists \n",
    "    * Split the input into steps and store in variable X\n",
    "    * Store the last of each of these variables into y\n",
    "    * Stop if the steps are greater than the lenght of the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import Accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split The Data into X and Y and Reshape the X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "n_steps = 3\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model \n",
    "    * LSTM layer\n",
    "    * Dense layer \n",
    "   \n",
    "   \n",
    "#### Show summary of the model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50)                10400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,451\n",
      "Trainable params: 10,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-15 15:15:13.153358: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-08-15 15:15:13.153401: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-08-15 15:15:13.153438: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (olamide): /proc/driver/nvidia/version does not exist\n",
      "2021-08-15 15:15:13.153845: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model on the Input X,y and predict on a test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103.03189]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change Values Of Epochs To 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101.92971]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=3, verbose=0)\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "# predict Next input\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(actual, predicted):\n",
    "    deviation = (actual-predicted)/actual\n",
    "    percentage = 100 - (deviation * 100)\n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage after 3 epochs : [98.10682]%\n"
     ]
    }
   ],
   "source": [
    "print(f'percentage after 3 epochs : {accuracy(yhat[0], array(100))}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101.9002]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=5, verbose=0)\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage after 5 epochs : 98.1915512084961%\n"
     ]
    }
   ],
   "source": [
    "print(f'percentage after 5 epochs : {accuracy(yhat[0], array(100))[0]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100.43257]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=10, verbose=0)\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage after 10 epochs : 99.56929016113281%\n"
     ]
    }
   ],
   "source": [
    "print(f'percentage after 10 epochs : {accuracy(yhat[0], array(100))[0]}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict The Next Two Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100.432076]\n",
      " [111.242516]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "x_input = array(([70, 80, 90], [80,90,100]))\n",
    "x_input = x_input.reshape((x_input.shape[0], x_input.shape[1], n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DML Workshop 06 - Text Generation using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-15 17:33:08.703621: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-15 17:33:08.703664: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Load LSTM network and generate text\n",
    "import sys\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "    Open word file and load text into memory\n",
    "    convert the text loaded into lowercase\n",
    "    sort the texts and remove recurring letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "filename = \"wonderland.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()\n",
    "# create mapping of unique chars to integers, and a reverse mapping\n",
    "chars = sorted(list(set(raw_text)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "    1. Map the unique characters to numbers and the unique numbers to characters\n",
    "    2. Now that the letters have been represented by numbers for training\n",
    "    3. The words are sliced into diffrent group (sentences) for Training\n",
    "    4. The next word after this is represented as the predicted variable\n",
    "    5. Then coverted to numbers , and seperated into Taarget and Input variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  148574\n",
      "Total Vocab:  46\n",
      "Total Patterns:  148474\n"
     ]
    }
   ],
   "source": [
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)\n",
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = raw_text[i:i + seq_length]\n",
    "\tseq_out = raw_text[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)\n",
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = to_categorical(dataY)\n",
    "# define the LSTM model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model \n",
    "    Define a sequential model \n",
    "    then add an lstm layer to learn the important words\n",
    "    Add Dropout to compensate overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-15 17:34:06.360306: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-15 17:34:06.360339: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-15 17:34:06.360363: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (olamide): /proc/driver/nvidia/version does not exist\n",
      "2022-01-15 17:34:06.360733: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model And Store Checkpoints (Where to pick up model training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.9446\n",
      "Epoch 00001: loss improved from inf to 2.94464, saving model to weights-improvement-01-2.9446.hdf5\n",
      "1160/1160 [==============================] - 422s 362ms/step - loss: 2.9446\n",
      "Epoch 2/5\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.7038\n",
      "Epoch 00002: loss improved from 2.94464 to 2.70384, saving model to weights-improvement-02-2.7038.hdf5\n",
      "1160/1160 [==============================] - 410s 353ms/step - loss: 2.7038\n",
      "Epoch 3/5\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.6012\n",
      "Epoch 00003: loss improved from 2.70384 to 2.60120, saving model to weights-improvement-03-2.6012.hdf5\n",
      "1160/1160 [==============================] - 402s 346ms/step - loss: 2.6012\n",
      "Epoch 4/5\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.5337\n",
      "Epoch 00004: loss improved from 2.60120 to 2.53374, saving model to weights-improvement-04-2.5337.hdf5\n",
      "1160/1160 [==============================] - 407s 351ms/step - loss: 2.5337\n",
      "Epoch 5/5\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.4748\n",
      "Epoch 00005: loss improved from 2.53374 to 2.47484, saving model to weights-improvement-05-2.4748.hdf5\n",
      "1160/1160 [==============================] - 395s 341ms/step - loss: 2.4748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f981acea3d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=5, batch_size=128, callbacks=callbacks_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate The Text Using The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\"  and washing--extra.\"'\n",
      "\n",
      "  `you couldn't have wanted it much,' said alice; `living at the\n",
      "bottom of t \"\n",
      "Generating Text\n",
      "he woeee                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-05-2.4748.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "print(\"Generating Text\")\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Number Of Epochs to 25\n",
    "    Checking the Accuracy\n",
    "    Accuracy Improves till 25 epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.4197 - accuracy: 0.3160\n",
      "Epoch 00001: loss improved from inf to 2.41969, saving model to weights-improfvement-01-2.4197.hdf5\n",
      "1160/1160 [==============================] - 385s 331ms/step - loss: 2.4197 - accuracy: 0.3160\n",
      "Epoch 2/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.3770 - accuracy: 0.3271\n",
      "Epoch 00002: loss improved from 2.41969 to 2.37696, saving model to weights-improfvement-02-2.3770.hdf5\n",
      "1160/1160 [==============================] - 388s 334ms/step - loss: 2.3770 - accuracy: 0.3271\n",
      "Epoch 3/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.3336 - accuracy: 0.3376\n",
      "Epoch 00003: loss improved from 2.37696 to 2.33356, saving model to weights-improfvement-03-2.3336.hdf5\n",
      "1160/1160 [==============================] - 391s 337ms/step - loss: 2.3336 - accuracy: 0.3376\n",
      "Epoch 4/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.2961 - accuracy: 0.3468\n",
      "Epoch 00004: loss improved from 2.33356 to 2.29609, saving model to weights-improfvement-04-2.2961.hdf5\n",
      "1160/1160 [==============================] - 395s 341ms/step - loss: 2.2961 - accuracy: 0.3468\n",
      "Epoch 5/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.2547 - accuracy: 0.3568\n",
      "Epoch 00005: loss improved from 2.29609 to 2.25467, saving model to weights-improfvement-05-2.2547.hdf5\n",
      "1160/1160 [==============================] - 395s 340ms/step - loss: 2.2547 - accuracy: 0.3568\n",
      "Epoch 6/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.2152 - accuracy: 0.3670\n",
      "Epoch 00006: loss improved from 2.25467 to 2.21521, saving model to weights-improfvement-06-2.2152.hdf5\n",
      "1160/1160 [==============================] - 418s 360ms/step - loss: 2.2152 - accuracy: 0.3670\n",
      "Epoch 7/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.1811 - accuracy: 0.3758\n",
      "Epoch 00007: loss improved from 2.21521 to 2.18109, saving model to weights-improfvement-07-2.1811.hdf5\n",
      "1160/1160 [==============================] - 413s 356ms/step - loss: 2.1811 - accuracy: 0.3758\n",
      "Epoch 8/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.1446 - accuracy: 0.3850\n",
      "Epoch 00008: loss improved from 2.18109 to 2.14463, saving model to weights-improfvement-08-2.1446.hdf5\n",
      "1160/1160 [==============================] - 414s 357ms/step - loss: 2.1446 - accuracy: 0.3850\n",
      "Epoch 9/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.1117 - accuracy: 0.3932\n",
      "Epoch 00009: loss improved from 2.14463 to 2.11168, saving model to weights-improfvement-09-2.1117.hdf5\n",
      "1160/1160 [==============================] - 419s 361ms/step - loss: 2.1117 - accuracy: 0.3932\n",
      "Epoch 10/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.0787 - accuracy: 0.4004\n",
      "Epoch 00010: loss improved from 2.11168 to 2.07869, saving model to weights-improfvement-10-2.0787.hdf5\n",
      "1160/1160 [==============================] - 415s 358ms/step - loss: 2.0787 - accuracy: 0.4004\n",
      "Epoch 11/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.0481 - accuracy: 0.4085\n",
      "Epoch 00011: loss improved from 2.07869 to 2.04813, saving model to weights-improfvement-11-2.0481.hdf5\n",
      "1160/1160 [==============================] - 411s 354ms/step - loss: 2.0481 - accuracy: 0.4085\n",
      "Epoch 12/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.0157 - accuracy: 0.4172\n",
      "Epoch 00012: loss improved from 2.04813 to 2.01571, saving model to weights-improfvement-12-2.0157.hdf5\n",
      "1160/1160 [==============================] - 412s 355ms/step - loss: 2.0157 - accuracy: 0.4172\n",
      "Epoch 13/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.9905 - accuracy: 0.4227\n",
      "Epoch 00013: loss improved from 2.01571 to 1.99054, saving model to weights-improfvement-13-1.9905.hdf5\n",
      "1160/1160 [==============================] - 413s 356ms/step - loss: 1.9905 - accuracy: 0.4227\n",
      "Epoch 14/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.9620 - accuracy: 0.4298\n",
      "Epoch 00014: loss improved from 1.99054 to 1.96201, saving model to weights-improfvement-14-1.9620.hdf5\n",
      "1160/1160 [==============================] - 413s 356ms/step - loss: 1.9620 - accuracy: 0.4298\n",
      "Epoch 15/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.9403 - accuracy: 0.4351\n",
      "Epoch 00015: loss improved from 1.96201 to 1.94033, saving model to weights-improfvement-15-1.9403.hdf5\n",
      "1160/1160 [==============================] - 413s 356ms/step - loss: 1.9403 - accuracy: 0.4351\n",
      "Epoch 16/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.9143 - accuracy: 0.4417\n",
      "Epoch 00016: loss improved from 1.94033 to 1.91431, saving model to weights-improfvement-16-1.9143.hdf5\n",
      "1160/1160 [==============================] - 413s 356ms/step - loss: 1.9143 - accuracy: 0.4417\n",
      "Epoch 17/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.8931 - accuracy: 0.4489\n",
      "Epoch 00017: loss improved from 1.91431 to 1.89313, saving model to weights-improfvement-17-1.8931.hdf5\n",
      "1160/1160 [==============================] - 414s 357ms/step - loss: 1.8931 - accuracy: 0.4489\n",
      "Epoch 18/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.8691 - accuracy: 0.4544\n",
      "Epoch 00018: loss improved from 1.89313 to 1.86906, saving model to weights-improfvement-18-1.8691.hdf5\n",
      "1160/1160 [==============================] - 414s 357ms/step - loss: 1.8691 - accuracy: 0.4544\n",
      "Epoch 19/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.8510 - accuracy: 0.4611\n",
      "Epoch 00019: loss improved from 1.86906 to 1.85104, saving model to weights-improfvement-19-1.8510.hdf5\n",
      "1160/1160 [==============================] - 414s 357ms/step - loss: 1.8510 - accuracy: 0.4611\n",
      "Epoch 20/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.8318 - accuracy: 0.4631\n",
      "Epoch 00020: loss improved from 1.85104 to 1.83177, saving model to weights-improfvement-20-1.8318.hdf5\n",
      "1160/1160 [==============================] - 414s 357ms/step - loss: 1.8318 - accuracy: 0.4631\n",
      "Epoch 21/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.8109 - accuracy: 0.4682\n",
      "Epoch 00021: loss improved from 1.83177 to 1.81093, saving model to weights-improfvement-21-1.8109.hdf5\n",
      "1160/1160 [==============================] - 415s 357ms/step - loss: 1.8109 - accuracy: 0.4682\n",
      "Epoch 22/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.7990 - accuracy: 0.4714\n",
      "Epoch 00022: loss improved from 1.81093 to 1.79903, saving model to weights-improfvement-22-1.7990.hdf5\n",
      "1160/1160 [==============================] - 415s 357ms/step - loss: 1.7990 - accuracy: 0.4714\n",
      "Epoch 23/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.7815 - accuracy: 0.4764\n",
      "Epoch 00023: loss improved from 1.79903 to 1.78153, saving model to weights-improfvement-23-1.7815.hdf5\n",
      "1160/1160 [==============================] - 414s 357ms/step - loss: 1.7815 - accuracy: 0.4764\n",
      "Epoch 24/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.7660 - accuracy: 0.4801\n",
      "Epoch 00024: loss improved from 1.78153 to 1.76602, saving model to weights-improfvement-24-1.7660.hdf5\n",
      "1160/1160 [==============================] - 415s 357ms/step - loss: 1.7660 - accuracy: 0.4801\n",
      "Epoch 25/25\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.7584 - accuracy: 0.4824\n",
      "Epoch 00025: loss improved from 1.76602 to 1.75841, saving model to weights-improfvement-25-1.7584.hdf5\n",
      "1160/1160 [==============================] - 414s 357ms/step - loss: 1.7584 - accuracy: 0.4824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f981977edc0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# define the checkpoint\n",
    "filepath=\"weights-improfvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=25, batch_size=128, callbacks=callbacks_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" he was close behind it when she turned the\n",
      "corner, but the rabbit was no longer to be seen:  she fou \"\n",
      "Generating Text\n",
      "nd the fad not to the tooe     `whu did tot taid to toee to toye\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improfvement-25-1.7584.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "print(\"Generating Text\")\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Numbers Of Epochs to 50\n",
    "    Accuracy improves till 41 epochs \n",
    "    no changes in accuracy after \n",
    "    Texts are meaningless "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.9399 - accuracy: 0.2016\n",
      "Epoch 00001: loss improved from inf to 2.93987, saving model to weights-improvemffent-01-2.9399.hdf5\n",
      "1160/1160 [==============================] - 343s 295ms/step - loss: 2.9399 - accuracy: 0.2016\n",
      "Epoch 2/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.7040 - accuracy: 0.2522\n",
      "Epoch 00002: loss improved from 2.93987 to 2.70396, saving model to weights-improvemffent-02-2.7040.hdf5\n",
      "1160/1160 [==============================] - 352s 304ms/step - loss: 2.7040 - accuracy: 0.2522\n",
      "Epoch 3/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.6088 - accuracy: 0.2740\n",
      "Epoch 00003: loss improved from 2.70396 to 2.60876, saving model to weights-improvemffent-03-2.6088.hdf5\n",
      "1160/1160 [==============================] - 356s 307ms/step - loss: 2.6088 - accuracy: 0.2740\n",
      "Epoch 4/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.5402 - accuracy: 0.2873\n",
      "Epoch 00004: loss improved from 2.60876 to 2.54017, saving model to weights-improvemffent-04-2.5402.hdf5\n",
      "1160/1160 [==============================] - 357s 308ms/step - loss: 2.5402 - accuracy: 0.2873\n",
      "Epoch 5/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.4790 - accuracy: 0.3008\n",
      "Epoch 00005: loss improved from 2.54017 to 2.47900, saving model to weights-improvemffent-05-2.4790.hdf5\n",
      "1160/1160 [==============================] - 355s 306ms/step - loss: 2.4790 - accuracy: 0.3008\n",
      "Epoch 6/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.4236 - accuracy: 0.3137\n",
      "Epoch 00006: loss improved from 2.47900 to 2.42364, saving model to weights-improvemffent-06-2.4236.hdf5\n",
      "1160/1160 [==============================] - 353s 304ms/step - loss: 2.4236 - accuracy: 0.3137\n",
      "Epoch 7/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.3761 - accuracy: 0.3266\n",
      "Epoch 00007: loss improved from 2.42364 to 2.37611, saving model to weights-improvemffent-07-2.3761.hdf5\n",
      "1160/1160 [==============================] - 361s 311ms/step - loss: 2.3761 - accuracy: 0.3266\n",
      "Epoch 8/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.3293 - accuracy: 0.3375\n",
      "Epoch 00008: loss improved from 2.37611 to 2.32935, saving model to weights-improvemffent-08-2.3293.hdf5\n",
      "1160/1160 [==============================] - 358s 308ms/step - loss: 2.3293 - accuracy: 0.3375\n",
      "Epoch 9/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.2851 - accuracy: 0.3493\n",
      "Epoch 00009: loss improved from 2.32935 to 2.28513, saving model to weights-improvemffent-09-2.2851.hdf5\n",
      "1160/1160 [==============================] - 359s 310ms/step - loss: 2.2851 - accuracy: 0.3493\n",
      "Epoch 10/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.2451 - accuracy: 0.3594\n",
      "Epoch 00010: loss improved from 2.28513 to 2.24512, saving model to weights-improvemffent-10-2.2451.hdf5\n",
      "1160/1160 [==============================] - 355s 306ms/step - loss: 2.2451 - accuracy: 0.3594\n",
      "Epoch 11/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.2069 - accuracy: 0.3688\n",
      "Epoch 00011: loss improved from 2.24512 to 2.20690, saving model to weights-improvemffent-11-2.2069.hdf5\n",
      "1160/1160 [==============================] - 355s 306ms/step - loss: 2.2069 - accuracy: 0.3688\n",
      "Epoch 12/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.1670 - accuracy: 0.3779\n",
      "Epoch 00012: loss improved from 2.20690 to 2.16701, saving model to weights-improvemffent-12-2.1670.hdf5\n",
      "1160/1160 [==============================] - 355s 306ms/step - loss: 2.1670 - accuracy: 0.3779\n",
      "Epoch 13/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.1308 - accuracy: 0.3878\n",
      "Epoch 00013: loss improved from 2.16701 to 2.13081, saving model to weights-improvemffent-13-2.1308.hdf5\n",
      "1160/1160 [==============================] - 354s 305ms/step - loss: 2.1308 - accuracy: 0.3878\n",
      "Epoch 14/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.0987 - accuracy: 0.3966\n",
      "Epoch 00014: loss improved from 2.13081 to 2.09866, saving model to weights-improvemffent-14-2.0987.hdf5\n",
      "1160/1160 [==============================] - 354s 305ms/step - loss: 2.0987 - accuracy: 0.3966\n",
      "Epoch 15/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.0648 - accuracy: 0.4041\n",
      "Epoch 00015: loss improved from 2.09866 to 2.06477, saving model to weights-improvemffent-15-2.0648.hdf5\n",
      "1160/1160 [==============================] - 354s 305ms/step - loss: 2.0648 - accuracy: 0.4041\n",
      "Epoch 16/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.0340 - accuracy: 0.4119\n",
      "Epoch 00016: loss improved from 2.06477 to 2.03402, saving model to weights-improvemffent-16-2.0340.hdf5\n",
      "1160/1160 [==============================] - 354s 305ms/step - loss: 2.0340 - accuracy: 0.4119\n",
      "Epoch 17/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.0044 - accuracy: 0.4203\n",
      "Epoch 00017: loss improved from 2.03402 to 2.00435, saving model to weights-improvemffent-17-2.0044.hdf5\n",
      "1160/1160 [==============================] - 354s 305ms/step - loss: 2.0044 - accuracy: 0.4203\n",
      "Epoch 18/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.9762 - accuracy: 0.4267\n",
      "Epoch 00018: loss improved from 2.00435 to 1.97621, saving model to weights-improvemffent-18-1.9762.hdf5\n",
      "1160/1160 [==============================] - 353s 304ms/step - loss: 1.9762 - accuracy: 0.4267\n",
      "Epoch 19/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.9497 - accuracy: 0.4338\n",
      "Epoch 00019: loss improved from 1.97621 to 1.94972, saving model to weights-improvemffent-19-1.9497.hdf5\n",
      "1160/1160 [==============================] - 352s 304ms/step - loss: 1.9497 - accuracy: 0.4338\n",
      "Epoch 20/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.9253 - accuracy: 0.4399\n",
      "Epoch 00020: loss improved from 1.94972 to 1.92531, saving model to weights-improvemffent-20-1.9253.hdf5\n",
      "1160/1160 [==============================] - 353s 304ms/step - loss: 1.9253 - accuracy: 0.4399\n",
      "Epoch 21/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.9032 - accuracy: 0.4459\n",
      "Epoch 00021: loss improved from 1.92531 to 1.90318, saving model to weights-improvemffent-21-1.9032.hdf5\n",
      "1160/1160 [==============================] - 353s 305ms/step - loss: 1.9032 - accuracy: 0.4459\n",
      "Epoch 22/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.8784 - accuracy: 0.4519\n",
      "Epoch 00022: loss improved from 1.90318 to 1.87840, saving model to weights-improvemffent-22-1.8784.hdf5\n",
      "1160/1160 [==============================] - 353s 304ms/step - loss: 1.8784 - accuracy: 0.4519\n",
      "Epoch 23/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.8548 - accuracy: 0.4595\n",
      "Epoch 00023: loss improved from 1.87840 to 1.85483, saving model to weights-improvemffent-23-1.8548.hdf5\n",
      "1160/1160 [==============================] - 352s 303ms/step - loss: 1.8548 - accuracy: 0.4595\n",
      "Epoch 24/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.8348 - accuracy: 0.4636\n",
      "Epoch 00024: loss improved from 1.85483 to 1.83476, saving model to weights-improvemffent-24-1.8348.hdf5\n",
      "1160/1160 [==============================] - 352s 303ms/step - loss: 1.8348 - accuracy: 0.4636\n",
      "Epoch 25/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.8183 - accuracy: 0.4673\n",
      "Epoch 00025: loss improved from 1.83476 to 1.81834, saving model to weights-improvemffent-25-1.8183.hdf5\n",
      "1160/1160 [==============================] - 352s 303ms/step - loss: 1.8183 - accuracy: 0.4673\n",
      "Epoch 26/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.8005 - accuracy: 0.4708\n",
      "Epoch 00026: loss improved from 1.81834 to 1.80048, saving model to weights-improvemffent-26-1.8005.hdf5\n",
      "1160/1160 [==============================] - 352s 304ms/step - loss: 1.8005 - accuracy: 0.4708\n",
      "Epoch 27/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.7822 - accuracy: 0.4764\n",
      "Epoch 00027: loss improved from 1.80048 to 1.78219, saving model to weights-improvemffent-27-1.7822.hdf5\n",
      "1160/1160 [==============================] - 353s 304ms/step - loss: 1.7822 - accuracy: 0.4764\n",
      "Epoch 28/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.7642 - accuracy: 0.4813\n",
      "Epoch 00028: loss improved from 1.78219 to 1.76418, saving model to weights-improvemffent-28-1.7642.hdf5\n",
      "1160/1160 [==============================] - 354s 305ms/step - loss: 1.7642 - accuracy: 0.4813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.7522 - accuracy: 0.4859\n",
      "Epoch 00029: loss improved from 1.76418 to 1.75215, saving model to weights-improvemffent-29-1.7522.hdf5\n",
      "1160/1160 [==============================] - 350s 302ms/step - loss: 1.7522 - accuracy: 0.4859\n",
      "Epoch 30/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.7373 - accuracy: 0.4888\n",
      "Epoch 00030: loss improved from 1.75215 to 1.73734, saving model to weights-improvemffent-30-1.7373.hdf5\n",
      "1160/1160 [==============================] - 350s 302ms/step - loss: 1.7373 - accuracy: 0.4888\n",
      "Epoch 31/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.7280 - accuracy: 0.4904\n",
      "Epoch 00031: loss improved from 1.73734 to 1.72803, saving model to weights-improvemffent-31-1.7280.hdf5\n",
      "1160/1160 [==============================] - 351s 302ms/step - loss: 1.7280 - accuracy: 0.4904\n",
      "Epoch 32/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.7134 - accuracy: 0.4940\n",
      "Epoch 00032: loss improved from 1.72803 to 1.71336, saving model to weights-improvemffent-32-1.7134.hdf5\n",
      "1160/1160 [==============================] - 350s 302ms/step - loss: 1.7134 - accuracy: 0.4940\n",
      "Epoch 33/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.7500 - accuracy: 0.4854\n",
      "Epoch 00033: loss did not improve from 1.71336\n",
      "1160/1160 [==============================] - 350s 302ms/step - loss: 1.7500 - accuracy: 0.4854\n",
      "Epoch 34/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.7137 - accuracy: 0.4944\n",
      "Epoch 00034: loss did not improve from 1.71336\n",
      "1160/1160 [==============================] - 351s 302ms/step - loss: 1.7137 - accuracy: 0.4944\n",
      "Epoch 35/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.6870 - accuracy: 0.5011\n",
      "Epoch 00035: loss improved from 1.71336 to 1.68696, saving model to weights-improvemffent-35-1.6870.hdf5\n",
      "1160/1160 [==============================] - 351s 302ms/step - loss: 1.6870 - accuracy: 0.5011\n",
      "Epoch 36/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.6718 - accuracy: 0.5053\n",
      "Epoch 00036: loss improved from 1.68696 to 1.67178, saving model to weights-improvemffent-36-1.6718.hdf5\n",
      "1160/1160 [==============================] - 351s 302ms/step - loss: 1.6718 - accuracy: 0.5053\n",
      "Epoch 37/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.6611 - accuracy: 0.5078\n",
      "Epoch 00037: loss improved from 1.67178 to 1.66113, saving model to weights-improvemffent-37-1.6611.hdf5\n",
      "1160/1160 [==============================] - 351s 303ms/step - loss: 1.6611 - accuracy: 0.5078\n",
      "Epoch 38/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.6504 - accuracy: 0.5094\n",
      "Epoch 00038: loss improved from 1.66113 to 1.65035, saving model to weights-improvemffent-38-1.6504.hdf5\n",
      "1160/1160 [==============================] - 351s 303ms/step - loss: 1.6504 - accuracy: 0.5094\n",
      "Epoch 39/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.6418 - accuracy: 0.5141\n",
      "Epoch 00039: loss improved from 1.65035 to 1.64180, saving model to weights-improvemffent-39-1.6418.hdf5\n",
      "1160/1160 [==============================] - 352s 303ms/step - loss: 1.6418 - accuracy: 0.5141\n",
      "Epoch 40/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.6356 - accuracy: 0.5149\n",
      "Epoch 00040: loss improved from 1.64180 to 1.63559, saving model to weights-improvemffent-40-1.6356.hdf5\n",
      "1160/1160 [==============================] - 352s 304ms/step - loss: 1.6356 - accuracy: 0.5149\n",
      "Epoch 41/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 1.6294 - accuracy: 0.5162\n",
      "Epoch 00041: loss improved from 1.63559 to 1.62941, saving model to weights-improvemffent-41-1.6294.hdf5\n",
      "1160/1160 [==============================] - 352s 304ms/step - loss: 1.6294 - accuracy: 0.5162\n",
      "Epoch 42/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.5777 - accuracy: 0.3132\n",
      "Epoch 00042: loss did not improve from 1.62941\n",
      "1160/1160 [==============================] - 353s 304ms/step - loss: 2.5777 - accuracy: 0.3132\n",
      "Epoch 43/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 3.1029 - accuracy: 0.1860\n",
      "Epoch 00043: loss did not improve from 1.62941\n",
      "1160/1160 [==============================] - 355s 306ms/step - loss: 3.1029 - accuracy: 0.1860\n",
      "Epoch 44/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.7992 - accuracy: 0.2372\n",
      "Epoch 00044: loss did not improve from 1.62941\n",
      "1160/1160 [==============================] - 356s 307ms/step - loss: 2.7992 - accuracy: 0.2372\n",
      "Epoch 45/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.7125 - accuracy: 0.2528\n",
      "Epoch 00045: loss did not improve from 1.62941\n",
      "1160/1160 [==============================] - 357s 308ms/step - loss: 2.7125 - accuracy: 0.2528\n",
      "Epoch 46/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.6638 - accuracy: 0.2606\n",
      "Epoch 00046: loss did not improve from 1.62941\n",
      "1160/1160 [==============================] - 357s 308ms/step - loss: 2.6638 - accuracy: 0.2606\n",
      "Epoch 47/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.6219 - accuracy: 0.2685\n",
      "Epoch 00047: loss did not improve from 1.62941\n",
      "1160/1160 [==============================] - 358s 308ms/step - loss: 2.6219 - accuracy: 0.2685\n",
      "Epoch 48/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.5887 - accuracy: 0.2737\n",
      "Epoch 00048: loss did not improve from 1.62941\n",
      "1160/1160 [==============================] - 358s 309ms/step - loss: 2.5887 - accuracy: 0.2737\n",
      "Epoch 49/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.5547 - accuracy: 0.2806\n",
      "Epoch 00049: loss did not improve from 1.62941\n",
      "1160/1160 [==============================] - 358s 309ms/step - loss: 2.5547 - accuracy: 0.2806\n",
      "Epoch 50/50\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 2.5202 - accuracy: 0.2907\n",
      "Epoch 00050: loss did not improve from 1.62941\n",
      "1160/1160 [==============================] - 359s 309ms/step - loss: 2.5202 - accuracy: 0.2907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0a30ce06d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# define the checkpoint\n",
    "filepath=\"weights-improvemffent-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=50, batch_size=128, callbacks=callbacks_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" oesn't matter much,' thought alice, `as all the arches\n",
      "are gone from this side of the ground.'  so s \"\n",
      "Generating Text\n",
      "he went on, `i mort titel at the ragtin in an in oittle horeer the rail of the war oo the taye aerer at the oadb (she in the tam   she mad shat the was setiing toeerle, and she celln it tae tut thin she was noteing toee theer the rage ou teye oi the court, and the had to line the rabe turt alrcer to the kand.\n",
      "\n",
      "                 *                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvemffent-41-1.6294.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "print(\"Generating Text\")\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking LSTM layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 3.0217 - accuracy: 0.1940\n",
      "Epoch 00001: loss improved from inf to 3.02171, saving model to weights-improevemffent-01-3.0217.hdf5\n",
      "1160/1160 [==============================] - 1530s 1s/step - loss: 3.0217 - accuracy: 0.1940\n",
      "Epoch 2/10\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 3.0176 - accuracy: 0.1945\n",
      "Epoch 00002: loss improved from 3.02171 to 3.01760, saving model to weights-improevemffent-02-3.0176.hdf5\n",
      "1160/1160 [==============================] - 1549s 1s/step - loss: 3.0176 - accuracy: 0.1945\n",
      "Epoch 3/10\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 3.0145 - accuracy: 0.1945\n",
      "Epoch 00003: loss improved from 3.01760 to 3.01449, saving model to weights-improevemffent-03-3.0145.hdf5\n",
      "1160/1160 [==============================] - 1561s 1s/step - loss: 3.0145 - accuracy: 0.1945\n",
      "Epoch 4/10\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 3.0144 - accuracy: 0.1945\n",
      "Epoch 00004: loss improved from 3.01449 to 3.01441, saving model to weights-improevemffent-04-3.0144.hdf5\n",
      "1160/1160 [==============================] - 1553s 1s/step - loss: 3.0144 - accuracy: 0.1945\n",
      "Epoch 5/10\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 3.0146 - accuracy: 0.1945\n",
      "Epoch 00005: loss did not improve from 3.01441\n",
      "1160/1160 [==============================] - 1562s 1s/step - loss: 3.0146 - accuracy: 0.1945\n",
      "Epoch 6/10\n",
      "1160/1160 [==============================] - ETA: 0s - loss: 3.0147 - accuracy: 0.1945\n",
      "Epoch 00006: loss did not improve from 3.01441\n",
      "1160/1160 [==============================] - 1567s 1s/step - loss: 3.0147 - accuracy: 0.1945\n",
      "Epoch 7/10\n",
      " 546/1160 [=============>................] - ETA: 13:52 - loss: 3.0160 - accuracy: 0.1941"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# define the checkpoint\n",
    "filepath=\"weights-improevemffent-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=10, batch_size=128, callbacks=callbacks_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generated Texts Makes more Sense \n",
    "LSTM learns the important information from the training data and generates a more meaningful text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\"  man, your majesty,' the hatter began, in a\n",
      "trembling voice, `--and i hadn't begun my tea--not above \"\n",
      "Generating Text\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improevemffent-04-3.0144.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "print(\"Generating Text\")\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7bbdb7504b61f73e546406c10f4b7e0c348fe2d3bd878c7d2aaf027e4f9543c1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
